{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faker in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (30.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from faker) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyodbc in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.34)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'PostgreSQL ODBC Driver(ANSI)', 'PostgreSQL ODBC Driver(UNICODE)', 'ODBC Driver 17 for SQL Server', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)', 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "print(pyodbc.drivers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: eralchemy in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (1.5.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (0.20.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy eralchemy graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "def execute_sql_script(cursor, script):\n",
    "    \"\"\"\n",
    "    Executes a SQL script, splitting on 'GO' batch separators.\n",
    "    \"\"\"\n",
    "    # Split the script into individual statements\n",
    "    statements = script.strip().split('GO')\n",
    "    \n",
    "    for statement in statements:\n",
    "        # Remove any leading/trailing whitespace\n",
    "        statement = statement.strip()\n",
    "        if statement:\n",
    "            try:\n",
    "                cursor.execute(statement)\n",
    "                cursor.commit()\n",
    "            except pyodbc.Error as e:\n",
    "                print(f\"Error executing statement:\\n{statement}\\nError: {e}\")\n",
    "                cursor.rollback()\n",
    "                raise\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'YourServerName'  # Replace with your server name\n",
    "    database = 'master'  # Connect to the master database to execute DROP/CREATE DATABASE commands\n",
    "    trusted_connection = 'yes'  # Use 'yes' for Windows Authentication, 'no' for SQL Server Authentication\n",
    "\n",
    "    # If using SQL Server Authentication, uncomment and set UID and PWD\n",
    "    # uid = 'your_username'\n",
    "    # pwd = 'your_password'\n",
    "\n",
    "    # Connection string\n",
    "    connection_string = (\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        f'Trusted_Connection={trusted_connection};'\n",
    "    )\n",
    "\n",
    "    # If using SQL Server Authentication, include UID and PWD\n",
    "    # connection_string += f'UID={uid};PWD={pwd};'\n",
    "\n",
    "    try:\n",
    "        # Connect to the SQL Server\n",
    "        conn = pyodbc.connect(connection_string, autocommit=True)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        print(\"Connected to SQL Server.\")\n",
    "\n",
    "        # SQL script to create the Chinook database\n",
    "        sql_script = \"\"\"\n",
    "        /*******************************************************************************\n",
    "           Chinook Database - Version 1.4.5\n",
    "           Script: Chinook_SqlServer.sql\n",
    "        ********************************************************************************/\n",
    "\n",
    "        /*******************************************************************************\n",
    "        ********************************************************************************/\n",
    "\n",
    "        /*******************************************************************************\n",
    "           Drop database if it exists\n",
    "        ********************************************************************************/\n",
    "        IF EXISTS (SELECT name FROM master.dbo.sysdatabases WHERE name = N'Chinook')\n",
    "        BEGIN\n",
    "            ALTER DATABASE [Chinook] SET SINGLE_USER WITH ROLLBACK IMMEDIATE;\n",
    "            DROP DATABASE [Chinook];\n",
    "        END\n",
    "\n",
    "        /*******************************************************************************\n",
    "           Create database\n",
    "        ********************************************************************************/\n",
    "        CREATE DATABASE [Chinook];\n",
    "\n",
    "        USE [Chinook];\n",
    "\n",
    "        /*******************************************************************************\n",
    "           Create Tables\n",
    "        ********************************************************************************/\n",
    "        CREATE TABLE [dbo].[Album]\n",
    "        (\n",
    "            [AlbumId] INT NOT NULL,\n",
    "            [Title] NVARCHAR(160) NOT NULL,\n",
    "            [ArtistId] INT NOT NULL,\n",
    "            CONSTRAINT [PK_Album] PRIMARY KEY CLUSTERED ([AlbumId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Artist]\n",
    "        (\n",
    "            [ArtistId] INT NOT NULL,\n",
    "            [Name] NVARCHAR(120),\n",
    "            CONSTRAINT [PK_Artist] PRIMARY KEY CLUSTERED ([ArtistId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Customer]\n",
    "        (\n",
    "            [CustomerId] INT NOT NULL,\n",
    "            [FirstName] NVARCHAR(40) NOT NULL,\n",
    "            [LastName] NVARCHAR(20) NOT NULL,\n",
    "            [Company] NVARCHAR(80),\n",
    "            [Address] NVARCHAR(70),\n",
    "            [City] NVARCHAR(40),\n",
    "            [State] NVARCHAR(40),\n",
    "            [Country] NVARCHAR(40),\n",
    "            [PostalCode] NVARCHAR(10),\n",
    "            [Phone] NVARCHAR(24),\n",
    "            [Fax] NVARCHAR(24),\n",
    "            [Email] NVARCHAR(60) NOT NULL,\n",
    "            [SupportRepId] INT,\n",
    "            CONSTRAINT [PK_Customer] PRIMARY KEY CLUSTERED ([CustomerId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Employee]\n",
    "        (\n",
    "            [EmployeeId] INT NOT NULL,\n",
    "            [LastName] NVARCHAR(20) NOT NULL,\n",
    "            [FirstName] NVARCHAR(20) NOT NULL,\n",
    "            [Title] NVARCHAR(30),\n",
    "            [ReportsTo] INT,\n",
    "            [BirthDate] DATETIME,\n",
    "            [HireDate] DATETIME,\n",
    "            [Address] NVARCHAR(70),\n",
    "            [City] NVARCHAR(40),\n",
    "            [State] NVARCHAR(40),\n",
    "            [Country] NVARCHAR(40),\n",
    "            [PostalCode] NVARCHAR(10),\n",
    "            [Phone] NVARCHAR(24),\n",
    "            [Fax] NVARCHAR(24),\n",
    "            [Email] NVARCHAR(60),\n",
    "            CONSTRAINT [PK_Employee] PRIMARY KEY CLUSTERED ([EmployeeId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Genre]\n",
    "        (\n",
    "            [GenreId] INT NOT NULL,\n",
    "            [Name] NVARCHAR(120),\n",
    "            CONSTRAINT [PK_Genre] PRIMARY KEY CLUSTERED ([GenreId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Invoice]\n",
    "        (\n",
    "            [InvoiceId] INT NOT NULL,\n",
    "            [CustomerId] INT NOT NULL,\n",
    "            [InvoiceDate] DATETIME NOT NULL,\n",
    "            [BillingAddress] NVARCHAR(70),\n",
    "            [BillingCity] NVARCHAR(40),\n",
    "            [BillingState] NVARCHAR(40),\n",
    "            [BillingCountry] NVARCHAR(40),\n",
    "            [BillingPostalCode] NVARCHAR(10),\n",
    "            [Total] NUMERIC(10,2) NOT NULL,\n",
    "            CONSTRAINT [PK_Invoice] PRIMARY KEY CLUSTERED ([InvoiceId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[InvoiceLine]\n",
    "        (\n",
    "            [InvoiceLineId] INT NOT NULL,\n",
    "            [InvoiceId] INT NOT NULL,\n",
    "            [TrackId] INT NOT NULL,\n",
    "            [UnitPrice] NUMERIC(10,2) NOT NULL,\n",
    "            [Quantity] INT NOT NULL,\n",
    "            CONSTRAINT [PK_InvoiceLine] PRIMARY KEY CLUSTERED ([InvoiceLineId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[MediaType]\n",
    "        (\n",
    "            [MediaTypeId] INT NOT NULL,\n",
    "            [Name] NVARCHAR(120),\n",
    "            CONSTRAINT [PK_MediaType] PRIMARY KEY CLUSTERED ([MediaTypeId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Playlist]\n",
    "        (\n",
    "            [PlaylistId] INT NOT NULL,\n",
    "            [Name] NVARCHAR(120),\n",
    "            CONSTRAINT [PK_Playlist] PRIMARY KEY CLUSTERED ([PlaylistId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[PlaylistTrack]\n",
    "        (\n",
    "            [PlaylistId] INT NOT NULL,\n",
    "            [TrackId] INT NOT NULL,\n",
    "            CONSTRAINT [PK_PlaylistTrack] PRIMARY KEY NONCLUSTERED ([PlaylistId], [TrackId])\n",
    "        );\n",
    "\n",
    "        CREATE TABLE [dbo].[Track]\n",
    "        (\n",
    "            [TrackId] INT NOT NULL,\n",
    "            [Name] NVARCHAR(200) NOT NULL,\n",
    "            [AlbumId] INT,\n",
    "            [MediaTypeId] INT NOT NULL,\n",
    "            [GenreId] INT,\n",
    "            [Composer] NVARCHAR(220),\n",
    "            [Milliseconds] INT NOT NULL,\n",
    "            [Bytes] INT,\n",
    "            [UnitPrice] NUMERIC(10,2) NOT NULL,\n",
    "            CONSTRAINT [PK_Track] PRIMARY KEY CLUSTERED ([TrackId])\n",
    "        );\n",
    "\n",
    "        /*******************************************************************************\n",
    "           Create Foreign Keys\n",
    "        ********************************************************************************/\n",
    "        ALTER TABLE [dbo].[Album] ADD CONSTRAINT [FK_AlbumArtistId]\n",
    "            FOREIGN KEY ([ArtistId]) REFERENCES [dbo].[Artist] ([ArtistId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_AlbumArtistId] ON [dbo].[Album] ([ArtistId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Customer] ADD CONSTRAINT [FK_CustomerSupportRepId]\n",
    "            FOREIGN KEY ([SupportRepId]) REFERENCES [dbo].[Employee] ([EmployeeId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_CustomerSupportRepId] ON [dbo].[Customer] ([SupportRepId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Employee] ADD CONSTRAINT [FK_EmployeeReportsTo]\n",
    "            FOREIGN KEY ([ReportsTo]) REFERENCES [dbo].[Employee] ([EmployeeId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_EmployeeReportsTo] ON [dbo].[Employee] ([ReportsTo]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Invoice] ADD CONSTRAINT [FK_InvoiceCustomerId]\n",
    "            FOREIGN KEY ([CustomerId]) REFERENCES [dbo].[Customer] ([CustomerId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_InvoiceCustomerId] ON [dbo].[Invoice] ([CustomerId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[InvoiceLine] ADD CONSTRAINT [FK_InvoiceLineInvoiceId]\n",
    "            FOREIGN KEY ([InvoiceId]) REFERENCES [dbo].[Invoice] ([InvoiceId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_InvoiceLineInvoiceId] ON [dbo].[InvoiceLine] ([InvoiceId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[InvoiceLine] ADD CONSTRAINT [FK_InvoiceLineTrackId]\n",
    "            FOREIGN KEY ([TrackId]) REFERENCES [dbo].[Track] ([TrackId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_InvoiceLineTrackId] ON [dbo].[InvoiceLine] ([TrackId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[PlaylistTrack] ADD CONSTRAINT [FK_PlaylistTrackPlaylistId]\n",
    "            FOREIGN KEY ([PlaylistId]) REFERENCES [dbo].[Playlist] ([PlaylistId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_PlaylistTrackPlaylistId] ON [dbo].[PlaylistTrack] ([PlaylistId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[PlaylistTrack] ADD CONSTRAINT [FK_PlaylistTrackTrackId]\n",
    "            FOREIGN KEY ([TrackId]) REFERENCES [dbo].[Track] ([TrackId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_PlaylistTrackTrackId] ON [dbo].[PlaylistTrack] ([TrackId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Track] ADD CONSTRAINT [FK_TrackAlbumId]\n",
    "            FOREIGN KEY ([AlbumId]) REFERENCES [dbo].[Album] ([AlbumId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_TrackAlbumId] ON [dbo].[Track] ([AlbumId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Track] ADD CONSTRAINT [FK_TrackGenreId]\n",
    "            FOREIGN KEY ([GenreId]) REFERENCES [dbo].[Genre] ([GenreId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_TrackGenreId] ON [dbo].[Track] ([GenreId]);\n",
    "\n",
    "        ALTER TABLE [dbo].[Track] ADD CONSTRAINT [FK_TrackMediaTypeId]\n",
    "            FOREIGN KEY ([MediaTypeId]) REFERENCES [dbo].[MediaType] ([MediaTypeId]) ON DELETE NO ACTION ON UPDATE NO ACTION;\n",
    "\n",
    "        CREATE INDEX [IFK_TrackMediaTypeId] ON [dbo].[Track] ([MediaTypeId]);\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the SQL script\n",
    "        execute_sql_script(cursor, sql_script)\n",
    "        print(\"Chinook database created successfully.\")\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the Chinook database.\n",
      "Generating the ERD...\n",
      "ERD generated and saved to chinook_erd.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from eralchemy import render_er\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\Graphviz\\bin\"\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'Chinook'\n",
    "    trusted_connection = 'yes'  # Use 'yes' for Windows Authentication, 'no' for SQL Server Authentication\n",
    "\n",
    "\n",
    "    # Create the connection string for SQLAlchemy\n",
    "    if trusted_connection == 'yes':\n",
    "        connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "    else:\n",
    "        connection_string = f'mssql+pyodbc://{uid}:{pwd}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    try:\n",
    "        engine = create_engine(connection_string)\n",
    "        print(\"Connected to the Chinook database.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error connecting to the database:\", e)\n",
    "        return\n",
    "\n",
    "    # Output file name\n",
    "    output_file = 'chinook_erd.png'\n",
    "\n",
    "    # Generate the ERD\n",
    "    try:\n",
    "        print(\"Generating the ERD...\")\n",
    "        render_er(connection_string, output_file)\n",
    "        print(f\"ERD generated and saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error generating the ERD:\", e)\n",
    "        return\n",
    "\n",
    "    # Open the ERD image\n",
    "    try:\n",
    "        if os.name == 'nt':  # For Windows\n",
    "            os.startfile(output_file)\n",
    "        elif os.name == 'posix':  # For Unix/Linux/Mac\n",
    "            os.system(f'open \"{output_file}\"')\n",
    "        else:\n",
    "            print(\"Please open the ERD image manually:\", output_file)\n",
    "    except Exception as e:\n",
    "        print(\"Error opening the ERD image:\", e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing table: Album\n",
      "No issues found in table Album.\n",
      "\n",
      "Analyzing table: Artist\n",
      "Issues found in table Artist:\n",
      "- Table Artist has 2 sets of duplicate records based on non-primary key columns.\n",
      "\n",
      "Analyzing table: Customer\n",
      "No issues found in table Customer.\n",
      "\n",
      "Analyzing table: Employee\n",
      "No issues found in table Employee.\n",
      "\n",
      "Analyzing table: Genre\n",
      "Issues found in table Genre:\n",
      "- Table Genre has 38 sets of duplicate records based on non-primary key columns.\n",
      "\n",
      "Analyzing table: Invoice\n",
      "Issues found in table Invoice:\n",
      "- Column InvoiceDate in table Invoice has 92 dates in the future.\n",
      "\n",
      "Analyzing table: InvoiceLine\n",
      "No issues found in table InvoiceLine.\n",
      "\n",
      "Analyzing table: MediaType\n",
      "Issues found in table MediaType:\n",
      "- Table MediaType has 19 sets of duplicate records based on non-primary key columns.\n",
      "\n",
      "Analyzing table: Playlist\n",
      "Issues found in table Playlist:\n",
      "- Table Playlist has 16 sets of duplicate records based on non-primary key columns.\n",
      "\n",
      "Analyzing table: PlaylistTrack\n",
      "No issues found in table PlaylistTrack.\n",
      "\n",
      "Analyzing table: Track\n",
      "No issues found in table Track.\n",
      "\n",
      "Analyzing table: sysdiagrams\n",
      "No issues found in table sysdiagrams.\n",
      "\n",
      "--- Data Quality Analysis Summary ---\n",
      "Total issues found: 5\n",
      "- Table Artist has 2 sets of duplicate records based on non-primary key columns.\n",
      "- Table Genre has 38 sets of duplicate records based on non-primary key columns.\n",
      "- Column InvoiceDate in table Invoice has 92 dates in the future.\n",
      "- Table MediaType has 19 sets of duplicate records based on non-primary key columns.\n",
      "- Table Playlist has 16 sets of duplicate records based on non-primary key columns.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    \"\"\"Establishes a connection to the SQL Server database.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "            f'SERVER={server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Trusted_Connection=yes;'\n",
    "        )\n",
    "        return conn\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error connecting to database:\", e)\n",
    "        sys.exit(1)\n",
    "\n",
    "def get_tables(cursor):\n",
    "    \"\"\"Retrieves a list of tables in the database.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT TABLE_NAME\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_CATALOG = ?\n",
    "    \"\"\", cursor.connection.getinfo(pyodbc.SQL_DATABASE_NAME))\n",
    "    tables = [row.TABLE_NAME for row in cursor.fetchall()]\n",
    "    return tables\n",
    "\n",
    "def get_non_nullable_columns(cursor, table_name):\n",
    "    \"\"\"Retrieves a list of non-nullable columns for a table.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.COLUMNS\n",
    "    WHERE TABLE_NAME = ? AND IS_NULLABLE = 'NO'\n",
    "    \"\"\", table_name)\n",
    "    columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    return columns\n",
    "\n",
    "def get_primary_keys(cursor, table_name):\n",
    "    \"\"\"Retrieves the primary key columns for a table.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT KU.COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS TC\n",
    "    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS KU\n",
    "        ON TC.CONSTRAINT_NAME = KU.CONSTRAINT_NAME\n",
    "    WHERE TC.TABLE_NAME = ? AND TC.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "    \"\"\", table_name)\n",
    "    pk_columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    return pk_columns\n",
    "\n",
    "def get_foreign_keys(cursor, table_name):\n",
    "    \"\"\"Retrieves foreign key relationships for a table.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT\n",
    "        FK.COLUMN_NAME,\n",
    "        PK.TABLE_NAME AS REFERENCED_TABLE_NAME,\n",
    "        PK.COLUMN_NAME AS REFERENCED_COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS C\n",
    "    INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE FK\n",
    "        ON C.CONSTRAINT_NAME = FK.CONSTRAINT_NAME\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            i1.TABLE_NAME,\n",
    "            i2.COLUMN_NAME\n",
    "        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS i1\n",
    "        INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE i2\n",
    "            ON i1.CONSTRAINT_NAME = i2.CONSTRAINT_NAME\n",
    "        WHERE i1.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "    ) PK\n",
    "        ON C.UNIQUE_CONSTRAINT_NAME = PK.TABLE_NAME\n",
    "    WHERE FK.TABLE_NAME = ?\n",
    "    \"\"\", table_name)\n",
    "    foreign_keys = cursor.fetchall()\n",
    "    return foreign_keys\n",
    "\n",
    "def check_nulls_in_non_nullable_columns(cursor, table_name):\n",
    "    \"\"\"Checks for NULLs in non-nullable columns.\"\"\"\n",
    "    non_nullable_columns = get_non_nullable_columns(cursor, table_name)\n",
    "    issues = []\n",
    "    for column in non_nullable_columns:\n",
    "        cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS NullCount\n",
    "        FROM {table_name}\n",
    "        WHERE {column} IS NULL\n",
    "        \"\"\")\n",
    "        null_count = cursor.fetchone().NullCount\n",
    "        if null_count > 0:\n",
    "            issues.append(f\"Column {column} in table {table_name} has {null_count} NULL values.\")\n",
    "    return issues\n",
    "\n",
    "def check_duplicate_primary_keys(cursor, table_name):\n",
    "    \"\"\"Checks for duplicate primary keys.\"\"\"\n",
    "    pk_columns = get_primary_keys(cursor, table_name)\n",
    "    if not pk_columns:\n",
    "        return []\n",
    "    columns_joined = ', '.join(pk_columns)\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT {columns_joined}, COUNT(*) AS Count\n",
    "    FROM {table_name}\n",
    "    GROUP BY {columns_joined}\n",
    "    HAVING COUNT(*) > 1\n",
    "    \"\"\")\n",
    "    duplicates = cursor.fetchall()\n",
    "    issues = []\n",
    "    if duplicates:\n",
    "        for dup in duplicates:\n",
    "            pk_values = ', '.join([f\"{col}={val}\" for col, val in zip(pk_columns, dup[:-1])])\n",
    "            issues.append(f\"Duplicate primary key in table {table_name}: {pk_values}, Count: {dup.Count}\")\n",
    "    return issues\n",
    "\n",
    "def check_foreign_key_violations(cursor, table_name):\n",
    "    \"\"\"Checks for foreign key violations.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT\n",
    "        FK.COLUMN_NAME,\n",
    "        FK.TABLE_NAME AS FK_TABLE_NAME,\n",
    "        PK.TABLE_NAME AS REFERENCED_TABLE_NAME,\n",
    "        PK.COLUMN_NAME AS REFERENCED_COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS C\n",
    "    INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE FK\n",
    "        ON C.CONSTRAINT_NAME = FK.CONSTRAINT_NAME\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            i1.CONSTRAINT_NAME,\n",
    "            i2.TABLE_NAME,\n",
    "            i2.COLUMN_NAME\n",
    "        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS i1\n",
    "        INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE i2\n",
    "            ON i1.CONSTRAINT_NAME = i2.CONSTRAINT_NAME\n",
    "        WHERE i1.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "    ) PK\n",
    "        ON C.UNIQUE_CONSTRAINT_NAME = PK.CONSTRAINT_NAME\n",
    "    WHERE FK.TABLE_NAME = ?\n",
    "    \"\"\", table_name)\n",
    "    foreign_keys = cursor.fetchall()\n",
    "    issues = []\n",
    "    for fk in foreign_keys:\n",
    "        fk_column = fk.COLUMN_NAME\n",
    "        fk_table = fk.FK_TABLE_NAME\n",
    "        pk_table = fk.REFERENCED_TABLE_NAME\n",
    "        pk_column = fk.REFERENCED_COLUMN_NAME\n",
    "        cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS ViolationCount\n",
    "        FROM {fk_table} f\n",
    "        LEFT JOIN {pk_table} p ON f.{fk_column} = p.{pk_column}\n",
    "        WHERE p.{pk_column} IS NULL AND f.{fk_column} IS NOT NULL\n",
    "        \"\"\")\n",
    "        violation_count = cursor.fetchone().ViolationCount\n",
    "        if violation_count > 0:\n",
    "            issues.append(f\"Foreign key violation in table {fk_table}.{fk_column} referencing {pk_table}.{pk_column}. Violations: {violation_count}\")\n",
    "    return issues\n",
    "\n",
    "def check_negative_values(cursor, table_name, columns):\n",
    "    \"\"\"Checks for negative values in specified columns.\"\"\"\n",
    "    issues = []\n",
    "    for column in columns:\n",
    "        cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS NegativeCount\n",
    "        FROM {table_name}\n",
    "        WHERE {column} < 0\n",
    "        \"\"\")\n",
    "        negative_count = cursor.fetchone().NegativeCount\n",
    "        if negative_count > 0:\n",
    "            issues.append(f\"Column {column} in table {table_name} has {negative_count} negative values.\")\n",
    "    return issues\n",
    "\n",
    "def check_future_dates(cursor, table_name, date_columns):\n",
    "    \"\"\"Checks for dates in the future.\"\"\"\n",
    "    issues = []\n",
    "    for column in date_columns:\n",
    "        cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS FutureDateCount\n",
    "        FROM {table_name}\n",
    "        WHERE {column} > GETDATE()\n",
    "        \"\"\")\n",
    "        future_date_count = cursor.fetchone().FutureDateCount\n",
    "        if future_date_count > 0:\n",
    "            issues.append(f\"Column {column} in table {table_name} has {future_date_count} dates in the future.\")\n",
    "    return issues\n",
    "\n",
    "def check_redundant_data(cursor, table_name):\n",
    "    \"\"\"Checks for redundant data (duplicate rows).\"\"\"\n",
    "    cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = ?\", table_name)\n",
    "    columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    pk_columns = get_primary_keys(cursor, table_name)\n",
    "    non_pk_columns = [col for col in columns if col not in pk_columns]\n",
    "    if not non_pk_columns:\n",
    "        return []\n",
    "    columns_joined = ', '.join(non_pk_columns)\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT {columns_joined}, COUNT(*) AS Count\n",
    "    FROM {table_name}\n",
    "    GROUP BY {columns_joined}\n",
    "    HAVING COUNT(*) > 1\n",
    "    \"\"\")\n",
    "    duplicates = cursor.fetchall()\n",
    "    issues = []\n",
    "    if duplicates:\n",
    "        issues.append(f\"Table {table_name} has {len(duplicates)} sets of duplicate records based on non-primary key columns.\")\n",
    "    return issues\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'Chinook'\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db(server, database)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve list of tables\n",
    "    tables = get_tables(cursor)\n",
    "\n",
    "    # Initialize an issues list\n",
    "    all_issues = []\n",
    "\n",
    "    # Analyze each table\n",
    "    for table in tables:\n",
    "        print(f\"\\nAnalyzing table: {table}\")\n",
    "        # Check for nulls in non-nullable columns\n",
    "        null_issues = check_nulls_in_non_nullable_columns(cursor, table)\n",
    "        # Check for duplicate primary keys\n",
    "        dup_pk_issues = check_duplicate_primary_keys(cursor, table)\n",
    "        # Check for foreign key violations\n",
    "        fk_issues = check_foreign_key_violations(cursor, table)\n",
    "        # Check for redundant data\n",
    "        redundant_issues = check_redundant_data(cursor, table)\n",
    "        # Check for negative values in specific columns\n",
    "        negative_issues = []\n",
    "        if table == 'InvoiceLine':\n",
    "            negative_issues += check_negative_values(cursor, table, ['UnitPrice', 'Quantity'])\n",
    "        elif table == 'Invoice':\n",
    "            negative_issues += check_negative_values(cursor, table, ['Total'])\n",
    "        elif table == 'Track':\n",
    "            negative_issues += check_negative_values(cursor, table, ['UnitPrice', 'Milliseconds', 'Bytes'])\n",
    "\n",
    "        # Check for future dates in date columns\n",
    "        date_issues = []\n",
    "        if table == 'Invoice':\n",
    "            date_issues += check_future_dates(cursor, table, ['InvoiceDate'])\n",
    "        elif table == 'Employee':\n",
    "            date_issues += check_future_dates(cursor, table, ['BirthDate', 'HireDate'])\n",
    "\n",
    "        # Collect all issues for the table\n",
    "        table_issues = null_issues + dup_pk_issues + fk_issues + redundant_issues + negative_issues + date_issues\n",
    "\n",
    "        if table_issues:\n",
    "            print(f\"Issues found in table {table}:\")\n",
    "            for issue in table_issues:\n",
    "                print(f\"- {issue}\")\n",
    "            all_issues.extend(table_issues)\n",
    "        else:\n",
    "            print(f\"No issues found in table {table}.\")\n",
    "\n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n--- Data Quality Analysis Summary ---\")\n",
    "    if all_issues:\n",
    "        print(f\"Total issues found: {len(all_issues)}\")\n",
    "        for issue in all_issues:\n",
    "            print(f\"- {issue}\")\n",
    "    else:\n",
    "        print(\"No data quality issues found in the database.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    \"\"\"Establishes a connection to the SQL Server database.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "            f'SERVER={server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Trusted_Connection=yes;'\n",
    "        )\n",
    "        return conn\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error connecting to database:\", e)\n",
    "        sys.exit(1)\n",
    "\n",
    "def fix_duplicate_records(conn, cursor, table_name):\n",
    "    \"\"\"\n",
    "    Identifies and removes duplicate records based on non-primary key columns.\n",
    "    Updates foreign key references to point to the kept record.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing duplicates in table: {table_name}\")\n",
    "    # Get all columns\n",
    "    cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = ?\", table_name)\n",
    "    columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    # Get primary key columns\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT KU.COLUMN_NAME\n",
    "        FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS TC\n",
    "        JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS KU\n",
    "            ON TC.CONSTRAINT_NAME = KU.CONSTRAINT_NAME\n",
    "        WHERE TC.TABLE_NAME = ? AND TC.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "        \"\"\", table_name)\n",
    "    pk_columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    if not pk_columns:\n",
    "        print(f\"No primary key defined for table {table_name}. Skipping.\")\n",
    "        return\n",
    "    # Non-primary key columns\n",
    "    non_pk_columns = [col for col in columns if col not in pk_columns]\n",
    "    if not non_pk_columns:\n",
    "        print(f\"No non-primary key columns to check for duplicates in table {table_name}.\")\n",
    "        return\n",
    "    # Find duplicates\n",
    "    columns_joined = ', '.join(non_pk_columns)\n",
    "    pk_column = pk_columns[0]  # Assuming single-column primary key\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT {columns_joined}, COUNT(*) AS Count, MIN({pk_column}) AS KeepId\n",
    "        FROM {table_name}\n",
    "        GROUP BY {columns_joined}\n",
    "        HAVING COUNT(*) > 1\n",
    "        \"\"\")\n",
    "    duplicates = cursor.fetchall()\n",
    "    if not duplicates:\n",
    "        print(f\"No duplicates found in table {table_name}.\")\n",
    "        return\n",
    "    print(f\"Found {len(duplicates)} sets of duplicate records in table {table_name}.\")\n",
    "    for dup in duplicates:\n",
    "        # Extract values\n",
    "        dup_values = dup[:-2]\n",
    "        count = dup.Count\n",
    "        keep_id = dup.KeepId\n",
    "        # Find all duplicate IDs except the one to keep\n",
    "        where_clause = ' AND '.join([f\"{col} = ?\" if dup_values[idx] is not None else f\"{col} IS NULL\"\n",
    "                                     for idx, col in enumerate(non_pk_columns)])\n",
    "        params = [val for val in dup_values if val is not None]\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT {pk_column}\n",
    "            FROM {table_name}\n",
    "            WHERE {where_clause} AND {pk_column} != ?\n",
    "            \"\"\", *params, keep_id)\n",
    "        duplicate_ids = [row[0] for row in cursor.fetchall()]\n",
    "        # Update foreign key references\n",
    "        update_foreign_keys(conn, cursor, table_name, pk_column, keep_id, duplicate_ids)\n",
    "        # Delete duplicate records\n",
    "        delete_ids(conn, cursor, table_name, pk_column, duplicate_ids)\n",
    "    print(f\"Duplicates resolved in table {table_name}.\")\n",
    "\n",
    "def update_foreign_keys(conn, cursor, table_name, pk_column, keep_id, duplicate_ids):\n",
    "    \"\"\"\n",
    "    Updates foreign key references from duplicate IDs to the kept ID.\n",
    "    \"\"\"\n",
    "    # Find tables that reference this table\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT FK.TABLE_NAME, FK.COLUMN_NAME\n",
    "        FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS C\n",
    "        INNER JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE FK\n",
    "            ON C.CONSTRAINT_NAME = FK.CONSTRAINT_NAME\n",
    "        WHERE C.UNIQUE_CONSTRAINT_NAME IN (\n",
    "            SELECT CONSTRAINT_NAME\n",
    "            FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS\n",
    "            WHERE TABLE_NAME = ? AND CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "        )\n",
    "        \"\"\", table_name)\n",
    "    referencing_tables = cursor.fetchall()\n",
    "    for ref in referencing_tables:\n",
    "        ref_table = ref.TABLE_NAME\n",
    "        ref_column = ref.COLUMN_NAME\n",
    "        print(f\"Updating foreign keys in {ref_table}.{ref_column}\")\n",
    "        # Update statements\n",
    "        for dup_id in duplicate_ids:\n",
    "            cursor.execute(f\"\"\"\n",
    "                UPDATE {ref_table}\n",
    "                SET {ref_column} = ?\n",
    "                WHERE {ref_column} = ?\n",
    "                \"\"\", keep_id, dup_id)\n",
    "            conn.commit()\n",
    "\n",
    "def delete_ids(conn, cursor, table_name, pk_column, ids_to_delete):\n",
    "    \"\"\"\n",
    "    Deletes records from a table based on a list of primary key IDs.\n",
    "    \"\"\"\n",
    "    if not ids_to_delete:\n",
    "        return\n",
    "    print(f\"Deleting {len(ids_to_delete)} records from {table_name}\")\n",
    "    placeholders = ', '.join(['?' for _ in ids_to_delete])\n",
    "    cursor.execute(f\"\"\"\n",
    "        DELETE FROM {table_name}\n",
    "        WHERE {pk_column} IN ({placeholders})\n",
    "        \"\"\", ids_to_delete)\n",
    "    conn.commit()\n",
    "\n",
    "def fix_future_dates(conn, cursor, table_name, date_column):\n",
    "    \"\"\"\n",
    "    Updates date values in the future to the current date or a logical date.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing future dates in table: {table_name}.{date_column}\")\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT COUNT(*) AS FutureDateCount\n",
    "        FROM {table_name}\n",
    "        WHERE {date_column} > GETDATE()\n",
    "        \"\"\")\n",
    "    future_date_count = cursor.fetchone().FutureDateCount\n",
    "    if future_date_count == 0:\n",
    "        print(f\"No future dates found in {table_name}.{date_column}.\")\n",
    "        return\n",
    "    print(f\"Found {future_date_count} future dates in {table_name}.{date_column}.\")\n",
    "    # Decide how to correct dates\n",
    "    # Option 1: Set to current date\n",
    "    # Option 2: Subtract a certain period\n",
    "    # Here, we'll set to current date\n",
    "    cursor.execute(f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET {date_column} = GETDATE()\n",
    "        WHERE {date_column} > GETDATE()\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "    print(f\"Future dates in {table_name}.{date_column} updated to current date.\")\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'Chinook'\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db(server, database)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Fix duplicate records in specified tables\n",
    "    tables_with_duplicates = ['Artist', 'Genre', 'MediaType', 'Playlist']\n",
    "    for table in tables_with_duplicates:\n",
    "        fix_duplicate_records(conn, cursor, table)\n",
    "\n",
    "    # Fix future dates in Invoice table\n",
    "    fix_future_dates(conn, cursor, 'Invoice', 'InvoiceDate')\n",
    "\n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"\\nData quality issues corrected successfully.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "- Album\n",
      "- Artist\n",
      "- Customer\n",
      "- Employee\n",
      "- Genre\n",
      "- Invoice\n",
      "- InvoiceLine\n",
      "- MediaType\n",
      "- Playlist\n",
      "- PlaylistTrack\n",
      "- Track\n",
      "- sysdiagrams\n",
      "\n",
      "Analyzing table: Album\n",
      "\n",
      "Schema of Album:\n",
      "- AlbumId: int(None), Nullable: NO\n",
      "- Title: nvarchar(160), Nullable: NO\n",
      "- ArtistId: int(None), Nullable: NO\n",
      "Album has 1168 rows.\n",
      "Primary Key(s) of Album: AlbumId\n",
      "Foreign Keys of Album:\n",
      "- ArtistId references Artist(ArtistId)\n",
      "\n",
      "Sample data from Album:\n",
      "   AlbumId                                  Title  ArtistId\n",
      "0        1  For Those About To Rock We Salute You         1\n",
      "1        2                      Balls to the Wall         2\n",
      "2        3                      Restless and Wild         2\n",
      "3        4                      Let There Be Rock         1\n",
      "4        5                               Big Ones         3\n",
      "\n",
      "Analyzing table: Artist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema of Artist:\n",
      "- ArtistId: int(None), Nullable: NO\n",
      "- Name: nvarchar(120), Nullable: YES\n",
      "Artist has 686 rows.\n",
      "Primary Key(s) of Artist: ArtistId\n",
      "No foreign keys found for Artist.\n",
      "\n",
      "Sample data from Artist:\n",
      "   ArtistId               Name\n",
      "0         1              AC/DC\n",
      "1         2             Accept\n",
      "2         3          Aerosmith\n",
      "3         4  Alanis Morissette\n",
      "4         5    Alice In Chains\n",
      "\n",
      "Analyzing table: Customer\n",
      "\n",
      "Schema of Customer:\n",
      "- CustomerId: int(None), Nullable: NO\n",
      "- FirstName: nvarchar(40), Nullable: NO\n",
      "- LastName: nvarchar(20), Nullable: NO\n",
      "- Company: nvarchar(80), Nullable: YES\n",
      "- Address: nvarchar(70), Nullable: YES\n",
      "- City: nvarchar(40), Nullable: YES\n",
      "- State: nvarchar(40), Nullable: YES\n",
      "- Country: nvarchar(40), Nullable: YES\n",
      "- PostalCode: nvarchar(10), Nullable: YES\n",
      "- Phone: nvarchar(24), Nullable: YES\n",
      "- Fax: nvarchar(24), Nullable: YES\n",
      "- Email: nvarchar(60), Nullable: NO\n",
      "- SupportRepId: int(None), Nullable: YES\n",
      "Customer has 874 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Key(s) of Customer: CustomerId\n",
      "Foreign Keys of Customer:\n",
      "- SupportRepId references Employee(EmployeeId)\n",
      "\n",
      "Sample data from Customer:\n",
      "   CustomerId  FirstName     LastName  \\\n",
      "0           1       Luís    Gonçalves   \n",
      "1           2     Leonie       Köhler   \n",
      "2           3   François     Tremblay   \n",
      "3           4      Bjørn       Hansen   \n",
      "4           5  František  Wichterlová   \n",
      "\n",
      "                                            Company  \\\n",
      "0  Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "1                                              None   \n",
      "2                                              None   \n",
      "3                                              None   \n",
      "4                                  JetBrains s.r.o.   \n",
      "\n",
      "                           Address                 City State         Country  \\\n",
      "0  Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP          Brazil   \n",
      "1          Theodor-Heuss-Straße 34            Stuttgart  None         Germany   \n",
      "2                1498 rue Bélanger             Montréal    QC          Canada   \n",
      "3                 Ullevålsveien 14                 Oslo  None          Norway   \n",
      "4                    Klanova 9/506               Prague  None  Czech Republic   \n",
      "\n",
      "  PostalCode               Phone                 Fax  \\\n",
      "0  12227-000  +55 (12) 3923-5555  +55 (12) 3923-5566   \n",
      "1      70174    +49 0711 2842222                None   \n",
      "2    H2G 1A7   +1 (514) 721-4711                None   \n",
      "3       0171     +47 22 44 22 22                None   \n",
      "4      14700    +420 2 4172 5555    +420 2 4172 5555   \n",
      "\n",
      "                      Email  SupportRepId  \n",
      "0      luisg@embraer.com.br             3  \n",
      "1     leonekohler@surfeu.de             5  \n",
      "2       ftremblay@gmail.com             3  \n",
      "3     bjorn.hansen@yahoo.no             4  \n",
      "4  frantisekw@jetbrains.com             4  \n",
      "\n",
      "Analyzing table: Employee\n",
      "\n",
      "Schema of Employee:\n",
      "- EmployeeId: int(None), Nullable: NO\n",
      "- LastName: nvarchar(20), Nullable: NO\n",
      "- FirstName: nvarchar(20), Nullable: NO\n",
      "- Title: nvarchar(30), Nullable: YES\n",
      "- ReportsTo: int(None), Nullable: YES\n",
      "- BirthDate: datetime(None), Nullable: YES\n",
      "- HireDate: datetime(None), Nullable: YES\n",
      "- Address: nvarchar(70), Nullable: YES\n",
      "- City: nvarchar(40), Nullable: YES\n",
      "- State: nvarchar(40), Nullable: YES\n",
      "- Country: nvarchar(40), Nullable: YES\n",
      "- PostalCode: nvarchar(10), Nullable: YES\n",
      "- Phone: nvarchar(24), Nullable: YES\n",
      "- Fax: nvarchar(24), Nullable: YES\n",
      "- Email: nvarchar(60), Nullable: YES\n",
      "Employee has 213 rows.\n",
      "Primary Key(s) of Employee: EmployeeId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign Keys of Employee:\n",
      "- ReportsTo references Employee(EmployeeId)\n",
      "\n",
      "Sample data from Employee:\n",
      "   EmployeeId LastName FirstName                Title  ReportsTo  BirthDate  \\\n",
      "0           1    Adams    Andrew      General Manager        NaN 1962-02-18   \n",
      "1           2  Edwards     Nancy        Sales Manager        1.0 1958-12-08   \n",
      "2           3  Peacock      Jane  Sales Support Agent        2.0 1973-08-29   \n",
      "3           4     Park  Margaret  Sales Support Agent        2.0 1947-09-19   \n",
      "4           5  Johnson     Steve  Sales Support Agent        2.0 1965-03-03   \n",
      "\n",
      "    HireDate              Address      City State Country PostalCode  \\\n",
      "0 2002-08-14  11120 Jasper Ave NW  Edmonton    AB  Canada    T5K 2N1   \n",
      "1 2002-05-01         825 8 Ave SW   Calgary    AB  Canada    T2P 2T3   \n",
      "2 2002-04-01        1111 6 Ave SW   Calgary    AB  Canada    T2P 5M5   \n",
      "3 2003-05-03     683 10 Street SW   Calgary    AB  Canada    T2P 5G3   \n",
      "4 2003-10-17         7727B 41 Ave   Calgary    AB  Canada    T3B 1Y7   \n",
      "\n",
      "               Phone                Fax                     Email  \n",
      "0  +1 (780) 428-9482  +1 (780) 428-3457    andrew@chinookcorp.com  \n",
      "1  +1 (403) 262-3443  +1 (403) 262-3322     nancy@chinookcorp.com  \n",
      "2  +1 (403) 262-3443  +1 (403) 262-6712      jane@chinookcorp.com  \n",
      "3  +1 (403) 263-4423  +1 (403) 263-4289  margaret@chinookcorp.com  \n",
      "4   1 (780) 836-9987   1 (780) 836-9543     steve@chinookcorp.com  \n",
      "\n",
      "Analyzing table: Genre\n",
      "\n",
      "Schema of Genre:\n",
      "- GenreId: int(None), Nullable: NO\n",
      "- Name: nvarchar(120), Nullable: YES\n",
      "Genre has 230 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Key(s) of Genre: GenreId\n",
      "No foreign keys found for Genre.\n",
      "\n",
      "Sample data from Genre:\n",
      "   GenreId                Name\n",
      "0        1                Rock\n",
      "1        2                Jazz\n",
      "2        3               Metal\n",
      "3        4  Alternative & Punk\n",
      "4        5       Rock And Roll\n",
      "\n",
      "Analyzing table: Invoice\n",
      "\n",
      "Schema of Invoice:\n",
      "- InvoiceId: int(None), Nullable: NO\n",
      "- CustomerId: int(None), Nullable: NO\n",
      "- InvoiceDate: datetime(None), Nullable: NO\n",
      "- BillingAddress: nvarchar(70), Nullable: YES\n",
      "- BillingCity: nvarchar(40), Nullable: YES\n",
      "- BillingState: nvarchar(40), Nullable: YES\n",
      "- BillingCountry: nvarchar(40), Nullable: YES\n",
      "- BillingPostalCode: nvarchar(10), Nullable: YES\n",
      "- Total: numeric(None), Nullable: NO\n",
      "Invoice has 1642 rows.\n",
      "Primary Key(s) of Invoice: InvoiceId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign Keys of Invoice:\n",
      "- CustomerId references Customer(CustomerId)\n",
      "\n",
      "Sample data from Invoice:\n",
      "   InvoiceId  CustomerId InvoiceDate           BillingAddress BillingCity  \\\n",
      "0          1           2  2021-01-01  Theodor-Heuss-Straße 34   Stuttgart   \n",
      "1          2           4  2021-01-02         Ullevålsveien 14        Oslo   \n",
      "2          3           8  2021-01-03          Grétrystraat 63    Brussels   \n",
      "3          4          14  2021-01-06           8210 111 ST NW    Edmonton   \n",
      "4          5          23  2021-01-11          69 Salem Street      Boston   \n",
      "\n",
      "  BillingState BillingCountry BillingPostalCode  Total  \n",
      "0         None        Germany             70174   1.98  \n",
      "1         None         Norway              0171   3.96  \n",
      "2         None        Belgium              1000   5.94  \n",
      "3           AB         Canada           T6G 2C7   8.91  \n",
      "4           MA            USA              2113  13.86  \n",
      "\n",
      "Analyzing table: InvoiceLine\n",
      "\n",
      "Schema of InvoiceLine:\n",
      "- InvoiceLineId: int(None), Nullable: NO\n",
      "- InvoiceId: int(None), Nullable: NO\n",
      "- TrackId: int(None), Nullable: NO\n",
      "- UnitPrice: numeric(None), Nullable: NO\n",
      "- Quantity: int(None), Nullable: NO\n",
      "InvoiceLine has 6340 rows.\n",
      "Primary Key(s) of InvoiceLine: InvoiceLineId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign Keys of InvoiceLine:\n",
      "- InvoiceId references Invoice(InvoiceId)\n",
      "- TrackId references Track(TrackId)\n",
      "\n",
      "Sample data from InvoiceLine:\n",
      "   InvoiceLineId  InvoiceId  TrackId  UnitPrice  Quantity\n",
      "0              1          1        2       0.99         1\n",
      "1              2          1        4       0.99         1\n",
      "2              3          2        6       0.99         1\n",
      "3              4          2        8       0.99         1\n",
      "4              5          2       10       0.99         1\n",
      "\n",
      "Analyzing table: MediaType\n",
      "\n",
      "Schema of MediaType:\n",
      "- MediaTypeId: int(None), Nullable: NO\n",
      "- Name: nvarchar(120), Nullable: YES\n",
      "MediaType has 128 rows.\n",
      "Primary Key(s) of MediaType: MediaTypeId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No foreign keys found for MediaType.\n",
      "\n",
      "Sample data from MediaType:\n",
      "   MediaTypeId                         Name\n",
      "0            1              MPEG audio file\n",
      "1            2     Protected AAC audio file\n",
      "2            3  Protected MPEG-4 video file\n",
      "3            4     Purchased AAC audio file\n",
      "4            5               AAC audio file\n",
      "\n",
      "Analyzing table: Playlist\n",
      "\n",
      "Schema of Playlist:\n",
      "- PlaylistId: int(None), Nullable: NO\n",
      "- Name: nvarchar(120), Nullable: YES\n",
      "Playlist has 223 rows.\n",
      "Primary Key(s) of Playlist: PlaylistId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No foreign keys found for Playlist.\n",
      "\n",
      "Sample data from Playlist:\n",
      "   PlaylistId        Name\n",
      "0           1       Music\n",
      "1           2      Movies\n",
      "2           3    TV Shows\n",
      "3           4  Audiobooks\n",
      "4           5  90’s Music\n",
      "\n",
      "Analyzing table: PlaylistTrack\n",
      "\n",
      "Schema of PlaylistTrack:\n",
      "- PlaylistId: int(None), Nullable: NO\n",
      "- TrackId: int(None), Nullable: NO\n",
      "PlaylistTrack has 10581 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Key(s) of PlaylistTrack: PlaylistId, TrackId\n",
      "Foreign Keys of PlaylistTrack:\n",
      "- PlaylistId references Playlist(PlaylistId)\n",
      "- TrackId references Track(TrackId)\n",
      "\n",
      "Sample data from PlaylistTrack:\n",
      "   PlaylistId  TrackId\n",
      "0           1     3402\n",
      "1           1     3389\n",
      "2           1     3390\n",
      "3           1     3391\n",
      "4           1     3392\n",
      "\n",
      "Analyzing table: Track\n",
      "\n",
      "Schema of Track:\n",
      "- TrackId: int(None), Nullable: NO\n",
      "- Name: nvarchar(200), Nullable: NO\n",
      "- AlbumId: int(None), Nullable: YES\n",
      "- MediaTypeId: int(None), Nullable: NO\n",
      "- GenreId: int(None), Nullable: YES\n",
      "- Composer: nvarchar(220), Nullable: YES\n",
      "- Milliseconds: int(None), Nullable: NO\n",
      "- Bytes: int(None), Nullable: YES\n",
      "- UnitPrice: numeric(None), Nullable: NO\n",
      "Track has 5554 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Key(s) of Track: TrackId\n",
      "Foreign Keys of Track:\n",
      "- AlbumId references Album(AlbumId)\n",
      "- GenreId references Genre(GenreId)\n",
      "- MediaTypeId references MediaType(MediaTypeId)\n",
      "\n",
      "Sample data from Track:\n",
      "   TrackId                                     Name  AlbumId  MediaTypeId  \\\n",
      "0        1  For Those About To Rock (We Salute You)        1            1   \n",
      "1        2                        Balls to the Wall        2            2   \n",
      "2        3                          Fast As a Shark        3            2   \n",
      "3        4                        Restless and Wild        3            2   \n",
      "4        5                     Princess of the Dawn        3            2   \n",
      "\n",
      "   GenreId                                           Composer  Milliseconds  \\\n",
      "0        1          Angus Young, Malcolm Young, Brian Johnson        343719   \n",
      "1        1  U. Dirkschneider, W. Hoffmann, H. Frank, P. Ba...        342562   \n",
      "2        1  F. Baltes, S. Kaufman, U. Dirkscneider & W. Ho...        230619   \n",
      "3        1  F. Baltes, R.A. Smith-Diesel, S. Kaufman, U. D...        252051   \n",
      "4        1                         Deaffy & R.A. Smith-Diesel        375418   \n",
      "\n",
      "      Bytes  UnitPrice  \n",
      "0  11170334       0.99  \n",
      "1   5510424       0.99  \n",
      "2   3990994       0.99  \n",
      "3   4331779       0.99  \n",
      "4   6290521       0.99  \n",
      "\n",
      "Analyzing table: sysdiagrams\n",
      "\n",
      "Schema of sysdiagrams:\n",
      "- name: nvarchar(128), Nullable: NO\n",
      "- principal_id: int(None), Nullable: NO\n",
      "- diagram_id: int(None), Nullable: NO\n",
      "- version: int(None), Nullable: YES\n",
      "- definition: varbinary(-1), Nullable: YES\n",
      "sysdiagrams has 1 rows.\n",
      "Primary Key(s) of sysdiagrams: diagram_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No foreign keys found for sysdiagrams.\n",
      "\n",
      "Sample data from sysdiagrams:\n",
      "        name  principal_id  diagram_id  version  \\\n",
      "0  Diagram_0             1           1        1   \n",
      "\n",
      "                                          definition  \n",
      "0  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...  \n",
      "\n",
      "--- Dimensional Modeling Steps ---\n",
      "\n",
      "Step 1: Selecting the Business Process\n",
      "The main business process is 'Sales Transactions'. We focus on customer purchases and sales of tracks.\n",
      "\n",
      "Step 2: Declaring the Grain\n",
      "We define the grain as 'One row per invoice line item (InvoiceLine)', representing each sold track.\n",
      "\n",
      "Step 3: Identifying Dimensions\n",
      "Based on the analysis, potential dimensions include:\n",
      "- Date (from Invoice.InvoiceDate)\n",
      "- Customer\n",
      "- Employee (Support Rep)\n",
      "- Track\n",
      "- Album\n",
      "- Artist\n",
      "- Genre\n",
      "- MediaType\n",
      "\n",
      "Step 4: Identifying Facts\n",
      "The measurable quantities (facts) include:\n",
      "- Quantity (InvoiceLine.Quantity)\n",
      "- Unit Price (InvoiceLine.UnitPrice)\n",
      "- Total Amount (calculated as Quantity * Unit Price)\n",
      "\n",
      "--- Proposed Data Warehouse Schema ---\n",
      "Fact Table:\n",
      "- FactSales\n",
      "  - Grain: One row per invoice line item\n",
      "  - Foreign Keys: DateKey, CustomerKey, EmployeeKey, TrackKey, AlbumKey, ArtistKey, GenreKey, MediaTypeKey\n",
      "  - Measures: Quantity, Unit Price, Total Amount\n",
      "\n",
      "Dimension Tables:\n",
      "- DimDate\n",
      "- DimCustomer\n",
      "- DimEmployee\n",
      "- DimTrack\n",
      "- DimAlbum\n",
      "- DimArtist\n",
      "- DimGenre\n",
      "- DimMediaType\n",
      "\n",
      "This schema will allow us to answer complex analytical queries such as:\n",
      "- Grouping customers by geographic region and calculating total spending and average order value.\n",
      "- Identifying the top-selling tracks, albums, and artists over a specified period, sorted by revenue or quantity sold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\695718822.py:93: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    \"\"\"Establishes a connection to the SQL Server database.\"\"\"\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def get_table_list(cursor):\n",
    "    \"\"\"Retrieves a list of tables in the database.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT TABLE_NAME\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "    \"\"\")\n",
    "    tables = [row.TABLE_NAME for row in cursor.fetchall()]\n",
    "    print(\"Tables in the database:\")\n",
    "    for table in tables:\n",
    "        print(f\"- {table}\")\n",
    "    return tables\n",
    "\n",
    "def get_table_schema(cursor, table_name):\n",
    "    \"\"\"Retrieves the schema of a table.\"\"\"\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COLUMN_NAME, \n",
    "        DATA_TYPE, \n",
    "        CHARACTER_MAXIMUM_LENGTH, \n",
    "        IS_NULLABLE\n",
    "    FROM INFORMATION_SCHEMA.COLUMNS\n",
    "    WHERE TABLE_NAME = '{table_name}'\n",
    "    \"\"\")\n",
    "    schema = cursor.fetchall()\n",
    "    print(f\"\\nSchema of {table_name}:\")\n",
    "    for col in schema:\n",
    "        print(f\"- {col.COLUMN_NAME}: {col.DATA_TYPE}({col.CHARACTER_MAXIMUM_LENGTH}), Nullable: {col.IS_NULLABLE}\")\n",
    "    return schema\n",
    "\n",
    "def get_row_count(cursor, table_name):\n",
    "    \"\"\"Retrieves the number of rows in a table.\"\"\"\n",
    "    cursor.execute(f\"SELECT COUNT(*) AS [RowCount] FROM {table_name}\")\n",
    "    row_count = cursor.fetchone().RowCount\n",
    "    print(f\"{table_name} has {row_count} rows.\")\n",
    "    return row_count\n",
    "\n",
    "def get_primary_keys(cursor, table_name):\n",
    "    \"\"\"Retrieves primary keys of a table.\"\"\"\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT KU.COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS TC\n",
    "    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS KU\n",
    "        ON TC.CONSTRAINT_NAME = KU.CONSTRAINT_NAME\n",
    "    WHERE TC.TABLE_NAME = '{table_name}' AND TC.CONSTRAINT_TYPE = 'PRIMARY KEY'\n",
    "    \"\"\")\n",
    "    pk = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    print(f\"Primary Key(s) of {table_name}: {', '.join(pk)}\")\n",
    "    return pk\n",
    "\n",
    "def get_foreign_keys(cursor, table_name):\n",
    "    \"\"\"Retrieves foreign keys of a table.\"\"\"\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT\n",
    "        KCU.COLUMN_NAME,\n",
    "        KCU.CONSTRAINT_NAME,\n",
    "        RC.UPDATE_RULE,\n",
    "        RC.DELETE_RULE,\n",
    "        KCU2.TABLE_NAME AS REFERENCED_TABLE_NAME,\n",
    "        KCU2.COLUMN_NAME AS REFERENCED_COLUMN_NAME\n",
    "    FROM INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS AS RC\n",
    "    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS KCU\n",
    "        ON KCU.CONSTRAINT_NAME = RC.CONSTRAINT_NAME\n",
    "    JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS KCU2\n",
    "        ON KCU2.CONSTRAINT_NAME = RC.UNIQUE_CONSTRAINT_NAME\n",
    "    WHERE KCU.TABLE_NAME = '{table_name}'\n",
    "    \"\"\")\n",
    "    fks = cursor.fetchall()\n",
    "    if fks:\n",
    "        print(f\"Foreign Keys of {table_name}:\")\n",
    "        for fk in fks:\n",
    "            print(f\"- {fk.COLUMN_NAME} references {fk.REFERENCED_TABLE_NAME}({fk.REFERENCED_COLUMN_NAME})\")\n",
    "    else:\n",
    "        print(f\"No foreign keys found for {table_name}.\")\n",
    "    return fks\n",
    "\n",
    "def explore_table_data(conn, table_name, limit=5):\n",
    "    \"\"\"Displays sample data from a table.\"\"\"\n",
    "    print(f\"\\nSample data from {table_name}:\")\n",
    "    df = pd.read_sql(f\"SELECT TOP {limit} * FROM {table_name}\", conn)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def analyze_table(conn, cursor, table_name):\n",
    "    \"\"\"Performs analysis on a table.\"\"\"\n",
    "    print(f\"\\nAnalyzing table: {table_name}\")\n",
    "    schema = get_table_schema(cursor, table_name)\n",
    "    row_count = get_row_count(cursor, table_name)\n",
    "    pk = get_primary_keys(cursor, table_name)\n",
    "    fks = get_foreign_keys(cursor, table_name)\n",
    "    sample_data = explore_table_data(conn, table_name)\n",
    "    return {\n",
    "        'schema': schema,\n",
    "        'row_count': row_count,\n",
    "        'primary_keys': pk,\n",
    "        'foreign_keys': fks,\n",
    "        'sample_data': sample_data\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'Chinook'\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = connect_to_db(server, database)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Retrieve list of tables\n",
    "    tables = get_table_list(cursor)\n",
    "    \n",
    "    # Analyze each table\n",
    "    table_analysis = {}\n",
    "    for table in tables:\n",
    "        table_analysis[table] = analyze_table(conn, cursor, table)\n",
    "    \n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    # Begin Dimensional Modeling Steps\n",
    "    print(\"\\n--- Dimensional Modeling Steps ---\")\n",
    "    # Step 1: Select the Business Process\n",
    "    print(\"\\nStep 1: Selecting the Business Process\")\n",
    "    print(\"The main business process is 'Sales Transactions'. We focus on customer purchases and sales of tracks.\")\n",
    "    \n",
    "    # Step 2: Declare the Grain\n",
    "    print(\"\\nStep 2: Declaring the Grain\")\n",
    "    print(\"We define the grain as 'One row per invoice line item (InvoiceLine)', representing each sold track.\")\n",
    "    \n",
    "    # Step 3: Identify the Dimensions\n",
    "    print(\"\\nStep 3: Identifying Dimensions\")\n",
    "    print(\"Based on the analysis, potential dimensions include:\")\n",
    "    print(\"- Date (from Invoice.InvoiceDate)\")\n",
    "    print(\"- Customer\")\n",
    "    print(\"- Employee (Support Rep)\")\n",
    "    print(\"- Track\")\n",
    "    print(\"- Album\")\n",
    "    print(\"- Artist\")\n",
    "    print(\"- Genre\")\n",
    "    print(\"- MediaType\")\n",
    "    \n",
    "    # Step 4: Identify the Facts\n",
    "    print(\"\\nStep 4: Identifying Facts\")\n",
    "    print(\"The measurable quantities (facts) include:\")\n",
    "    print(\"- Quantity (InvoiceLine.Quantity)\")\n",
    "    print(\"- Unit Price (InvoiceLine.UnitPrice)\")\n",
    "    print(\"- Total Amount (calculated as Quantity * Unit Price)\")\n",
    "    \n",
    "    # Summarize the proposed data warehouse schema\n",
    "    print(\"\\n--- Proposed Data Warehouse Schema ---\")\n",
    "    print(\"Fact Table:\")\n",
    "    print(\"- FactSales\")\n",
    "    print(\"  - Grain: One row per invoice line item\")\n",
    "    print(\"  - Foreign Keys: DateKey, CustomerKey, EmployeeKey, TrackKey, AlbumKey, ArtistKey, GenreKey, MediaTypeKey\")\n",
    "    print(\"  - Measures: Quantity, Unit Price, Total Amount\")\n",
    "    \n",
    "    print(\"\\nDimension Tables:\")\n",
    "    print(\"- DimDate\")\n",
    "    print(\"- DimCustomer\")\n",
    "    print(\"- DimEmployee\")\n",
    "    print(\"- DimTrack\")\n",
    "    print(\"- DimAlbum\")\n",
    "    print(\"- DimArtist\")\n",
    "    print(\"- DimGenre\")\n",
    "    print(\"- DimMediaType\")\n",
    "    \n",
    "    print(\"\\nThis schema will allow us to answer complex analytical queries such as:\")\n",
    "    print(\"- Grouping customers by geographic region and calculating total spending and average order value.\")\n",
    "    print(\"- Identifying the top-selling tracks, albums, and artists over a specified period, sorted by revenue or quantity sold.\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'ChinookDW_ETL_Task' scheduled successfully to run daily at 02:00.\n",
      "Batch file created at C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ChinookDW_ETL_Task.bat\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def schedule_task(task_name, notebook_path, time='02:00'):\n",
    "    python_executable = sys.executable  # Path to the current Python interpreter\n",
    "\n",
    "    # Ensure the notebook path is absolute\n",
    "    notebook_path = os.path.abspath(notebook_path)\n",
    "\n",
    "    # Construct the command to execute the notebook\n",
    "    command_to_run = f'\"{python_executable}\" -m jupyter nbconvert --ExecutePreprocessor.timeout=-1 --to notebook --execute \"{notebook_path}\" --output \"{notebook_path}\"'\n",
    "\n",
    "    # Create a batch file with the command\n",
    "    batch_file_path = os.path.join(tempfile.gettempdir(), f'{task_name}.bat')\n",
    "\n",
    "    with open(batch_file_path, 'w') as batch_file:\n",
    "        batch_file.write(f'@echo off\\n{command_to_run}\\n')\n",
    "\n",
    "    # Construct the command to create a scheduled task\n",
    "    command = [\n",
    "        'schtasks',\n",
    "        '/Create',\n",
    "        '/SC', 'DAILY',              # Schedule type: Daily\n",
    "        '/TN', task_name,            # Task name\n",
    "        '/TR', f'\"{batch_file_path}\"',  # Task to run\n",
    "        '/ST', time,                 # Start time\n",
    "        '/F'                         # Forcefully create the task and overwrite if it exists\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        output = subprocess.check_output(command, stderr=subprocess.STDOUT)\n",
    "        print(f\"Task '{task_name}' scheduled successfully to run daily at {time}.\")\n",
    "        print(f\"Batch file created at {batch_file_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to schedule task '{task_name}'.\")\n",
    "        print(e.output.decode())\n",
    "\n",
    "def main():\n",
    "    # Specify the Jupyter notebook filename\n",
    "    notebook_filename = 'ChinookDW4.ipynb'  # Replace with your notebook filename\n",
    "    notebook_path = os.path.abspath(notebook_filename)\n",
    "    task_name = 'ChinookDW_ETL_Task'        # Name for the scheduled task\n",
    "    run_time = '02:00'                      # Time to run the task daily (24-hour format)\n",
    "\n",
    "    # Check if the notebook exists\n",
    "    if not os.path.exists(notebook_path):\n",
    "        print(f\"Notebook not found at {notebook_path}. Please check the path and try again.\")\n",
    "        return\n",
    "\n",
    "    schedule_task(task_name, notebook_path, run_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch file: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ChinookDW_ETL_Task.bat\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_batch_file(batch_file_path):\n",
    "    # Ensure the batch file path is absolute\n",
    "    batch_file_path = os.path.abspath(batch_file_path)\n",
    "\n",
    "    if not os.path.exists(batch_file_path):\n",
    "        print(f\"Batch file not found at {batch_file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Running batch file: {batch_file_path}\")\n",
    "\n",
    "    # Run the batch file and capture output\n",
    "    try:\n",
    "        output = subprocess.check_output(batch_file_path, stderr=subprocess.STDOUT, shell=True, universal_newlines=True)\n",
    "        print(\"Batch file executed successfully.\\n\")\n",
    "        print(\"Output from batch file execution:\\n\")\n",
    "        print(output)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during batch file execution:\")\n",
    "        print(e.output)\n",
    "\n",
    "def main():\n",
    "    # Specify the batch file path\n",
    "    batch_file_path = os.path.join(os.environ['TEMP'], 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Temp\\\\ChinookDW_ETL_Task.bat')  # Adjust if stored elsewhere\n",
    "\n",
    "    run_batch_file(batch_file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbclient import NotebookClient\n",
    "from nbclient.exceptions import CellExecutionError\n",
    "import os\n",
    "\n",
    "def run_notebook(notebook_path):\n",
    "    # Ensure the notebook path is absolute\n",
    "    notebook_path = os.path.abspath(notebook_path)\n",
    "\n",
    "    if not os.path.exists(notebook_path):\n",
    "        print(f\"Notebook not found at {notebook_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Running notebook: {notebook_path}\")\n",
    "\n",
    "    # Load the notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Create a notebook client\n",
    "    client = NotebookClient(nb, timeout=-1, kernel_name='python3')\n",
    "\n",
    "    try:\n",
    "        # Execute the notebook\n",
    "        client.execute()\n",
    "        print(\"Notebook executed successfully.\\n\")\n",
    "    except CellExecutionError as e:\n",
    "        print(\"Error during notebook execution:\")\n",
    "        print(str(e))\n",
    "        return\n",
    "\n",
    "    # List all outputs\n",
    "    print(\"Listing all outputs generated during notebook execution:\\n\")\n",
    "    for cell in nb.cells:\n",
    "        if 'outputs' in cell:\n",
    "            for output in cell.outputs:\n",
    "                if output.output_type == 'stream':\n",
    "                    print(output.text)\n",
    "                elif output.output_type == 'execute_result':\n",
    "                    print(output.data.get('text/plain', ''))\n",
    "                elif output.output_type == 'error':\n",
    "                    print('Error:', ''.join(output.traceback))\n",
    "    print(\"Notebook output listing completed.\")\n",
    "\n",
    "def main():\n",
    "    # Specify the Jupyter notebook filename\n",
    "    notebook_filename = 'ChinookDW4.ipynb'  # Replace with your notebook filename\n",
    "    notebook_path = os.path.abspath(notebook_filename)\n",
    "\n",
    "    run_notebook(notebook_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 10 artists...\n",
      "Inserting 5 genres...\n",
      "Inserting 3 media types...\n",
      "Inserting 20 albums...\n",
      "Inserting 50 tracks...\n",
      "Inserting 5 employees...\n",
      "Inserting 15 customers...\n",
      "Inserting 30 invoices...\n",
      "Inserting 100 invoice lines...\n",
      "Inserting 5 playlists...\n",
      "Inserting 50 playlist tracks...\n",
      "Data insertion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def truncate_string(value, max_length):\n",
    "    if value is None:\n",
    "        return None\n",
    "    return value[:max_length]\n",
    "\n",
    "def insert_artists(cursor, num_records):\n",
    "    print(f\"Inserting {num_records} artists...\")\n",
    "    faker = Faker()\n",
    "    artist_ids = []\n",
    "    for _ in range(num_records):\n",
    "        name = truncate_string(faker.name(), 120)  # NVARCHAR(120)\n",
    "        cursor.execute(\"SELECT MAX(ArtistId) FROM Artist\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        artist_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"INSERT INTO Artist (ArtistId, Name) VALUES (?, ?)\", artist_id, name)\n",
    "        artist_ids.append(artist_id)\n",
    "    return artist_ids\n",
    "\n",
    "def insert_albums(cursor, artist_ids, num_records):\n",
    "    print(f\"Inserting {num_records} albums...\")\n",
    "    faker = Faker()\n",
    "    album_ids = []\n",
    "    for _ in range(num_records):\n",
    "        title = truncate_string(faker.sentence(nb_words=3), 160)  # NVARCHAR(160)\n",
    "        artist_id = random.choice(artist_ids)\n",
    "        cursor.execute(\"SELECT MAX(AlbumId) FROM Album\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        album_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"INSERT INTO Album (AlbumId, Title, ArtistId) VALUES (?, ?, ?)\", album_id, title, artist_id)\n",
    "        album_ids.append(album_id)\n",
    "    return album_ids\n",
    "\n",
    "def insert_genres(cursor, num_records):\n",
    "    print(f\"Inserting {num_records} genres...\")\n",
    "    faker = Faker()\n",
    "    genre_ids = []\n",
    "    for _ in range(num_records):\n",
    "        name = truncate_string(faker.word().capitalize(), 120)  # NVARCHAR(120)\n",
    "        cursor.execute(\"SELECT MAX(GenreId) FROM Genre\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        genre_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"INSERT INTO Genre (GenreId, Name) VALUES (?, ?)\", genre_id, name)\n",
    "        genre_ids.append(genre_id)\n",
    "    return genre_ids\n",
    "\n",
    "def insert_mediatypes(cursor, num_records):\n",
    "    print(f\"Inserting {num_records} media types...\")\n",
    "    faker = Faker()\n",
    "    mediatype_ids = []\n",
    "    for _ in range(num_records):\n",
    "        name = truncate_string(faker.word().capitalize(), 120)  # NVARCHAR(120)\n",
    "        cursor.execute(\"SELECT MAX(MediaTypeId) FROM MediaType\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        mediatype_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"INSERT INTO MediaType (MediaTypeId, Name) VALUES (?, ?)\", mediatype_id, name)\n",
    "        mediatype_ids.append(mediatype_id)\n",
    "    return mediatype_ids\n",
    "\n",
    "def insert_tracks(cursor, album_ids, genre_ids, mediatype_ids, num_records):\n",
    "    print(f\"Inserting {num_records} tracks...\")\n",
    "    faker = Faker()\n",
    "    track_ids = []\n",
    "    for _ in range(num_records):\n",
    "        name = truncate_string(faker.sentence(nb_words=4), 200)  # NVARCHAR(200)\n",
    "        album_id = random.choice(album_ids)\n",
    "        mediatype_id = random.choice(mediatype_ids)\n",
    "        genre_id = random.choice(genre_ids)\n",
    "        composer = truncate_string(faker.name(), 220)  # NVARCHAR(220)\n",
    "        milliseconds = random.randint(60000, 300000)\n",
    "        bytes_size = milliseconds * random.randint(50, 150)\n",
    "        unit_price = round(random.uniform(0.99, 1.99), 2)\n",
    "        cursor.execute(\"SELECT MAX(TrackId) FROM Track\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        track_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Track (TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", track_id, name, album_id, mediatype_id, genre_id, composer, milliseconds, bytes_size, unit_price)\n",
    "        track_ids.append(track_id)\n",
    "    return track_ids\n",
    "\n",
    "def insert_employees(cursor, num_records):\n",
    "    print(f\"Inserting {num_records} employees...\")\n",
    "    faker = Faker()\n",
    "    employee_ids = []\n",
    "    for _ in range(num_records):\n",
    "        first_name = truncate_string(faker.first_name(), 20)  # NVARCHAR(20)\n",
    "        last_name = truncate_string(faker.last_name(), 20)    # NVARCHAR(20)\n",
    "        title = truncate_string(random.choice(['Sales Manager', 'Sales Support Agent', 'IT Manager', 'IT Staff']), 30)  # NVARCHAR(30)\n",
    "        reports_to = None  # For simplicity\n",
    "        birth_date = faker.date_between(start_date='-60y', end_date='-25y')\n",
    "        hire_date = faker.date_between(start_date='-20y', end_date='today')\n",
    "        address = truncate_string(faker.street_address(), 70)  # NVARCHAR(70)\n",
    "        city = truncate_string(faker.city(), 40)               # NVARCHAR(40)\n",
    "        state = truncate_string(faker.state(), 40)             # NVARCHAR(40)\n",
    "        country = truncate_string(faker.country(), 40)         # NVARCHAR(40)\n",
    "        postal_code = truncate_string(faker.postcode(), 10)    # NVARCHAR(10)\n",
    "        phone = truncate_string(faker.phone_number(), 24)      # NVARCHAR(24)\n",
    "        fax = truncate_string(faker.phone_number(), 24)        # NVARCHAR(24)\n",
    "        email = truncate_string(faker.email(), 60)             # NVARCHAR(60)\n",
    "        cursor.execute(\"SELECT MAX(EmployeeId) FROM Employee\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        employee_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Employee (EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate,\n",
    "                                  Address, City, State, Country, PostalCode, Phone, Fax, Email)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", employee_id, last_name, first_name, title, reports_to, birth_date, hire_date,\n",
    "             address, city, state, country, postal_code, phone, fax, email)\n",
    "        employee_ids.append(employee_id)\n",
    "    return employee_ids\n",
    "\n",
    "def insert_customers(cursor, employee_ids, num_records):\n",
    "    print(f\"Inserting {num_records} customers...\")\n",
    "    faker = Faker()\n",
    "    customer_ids = []\n",
    "    for _ in range(num_records):\n",
    "        first_name = truncate_string(faker.first_name(), 40)  # NVARCHAR(40)\n",
    "        last_name = truncate_string(faker.last_name(), 20)    # NVARCHAR(20)\n",
    "        company = truncate_string(faker.company(), 80)        # NVARCHAR(80)\n",
    "        address = truncate_string(faker.street_address(), 70) # NVARCHAR(70)\n",
    "        city = truncate_string(faker.city(), 40)              # NVARCHAR(40)\n",
    "        state = truncate_string(faker.state(), 40)            # NVARCHAR(40)\n",
    "        country = truncate_string(faker.country(), 40)        # NVARCHAR(40)\n",
    "        postal_code = truncate_string(faker.postcode(), 10)   # NVARCHAR(10)\n",
    "        phone = truncate_string(faker.phone_number(), 24)     # NVARCHAR(24)\n",
    "        fax = truncate_string(faker.phone_number(), 24)       # NVARCHAR(24)\n",
    "        email = truncate_string(faker.email(), 60)            # NVARCHAR(60)\n",
    "        support_rep_id = random.choice(employee_ids) if employee_ids else None\n",
    "        cursor.execute(\"SELECT MAX(CustomerId) FROM Customer\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        customer_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Customer (CustomerId, FirstName, LastName, Company, Address, City, State,\n",
    "                                  Country, PostalCode, Phone, Fax, Email, SupportRepId)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", customer_id, first_name, last_name, company, address, city, state,\n",
    "             country, postal_code, phone, fax, email, support_rep_id)\n",
    "        customer_ids.append(customer_id)\n",
    "    return customer_ids\n",
    "\n",
    "def insert_invoices(cursor, customer_ids, num_records):\n",
    "    print(f\"Inserting {num_records} invoices...\")\n",
    "    faker = Faker()\n",
    "    invoice_ids = []\n",
    "    for _ in range(num_records):\n",
    "        customer_id = random.choice(customer_ids)\n",
    "        invoice_date = faker.date_between(start_date='-5y', end_date='today')\n",
    "        billing_address = truncate_string(faker.street_address(), 70)  # NVARCHAR(70)\n",
    "        billing_city = truncate_string(faker.city(), 40)               # NVARCHAR(40)\n",
    "        billing_state = truncate_string(faker.state(), 40)             # NVARCHAR(40)\n",
    "        billing_country = truncate_string(faker.country(), 40)         # NVARCHAR(40)\n",
    "        billing_postal_code = truncate_string(faker.postcode(), 10)    # NVARCHAR(10)\n",
    "        total = round(random.uniform(10.00, 500.00), 2)\n",
    "        cursor.execute(\"SELECT MAX(InvoiceId) FROM Invoice\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        invoice_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Invoice (InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity,\n",
    "                                 BillingState, BillingCountry, BillingPostalCode, Total)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", invoice_id, customer_id, invoice_date, billing_address, billing_city,\n",
    "             billing_state, billing_country, billing_postal_code, total)\n",
    "        invoice_ids.append(invoice_id)\n",
    "    return invoice_ids\n",
    "\n",
    "def insert_invoicelines(cursor, invoice_ids, track_ids, num_records):\n",
    "    print(f\"Inserting {num_records} invoice lines...\")\n",
    "    invoice_line_ids = []\n",
    "    for _ in range(num_records):\n",
    "        invoice_id = random.choice(invoice_ids)\n",
    "        track_id = random.choice(track_ids)\n",
    "        unit_price = round(random.uniform(0.99, 1.99), 2)\n",
    "        quantity = random.randint(1, 5)\n",
    "        cursor.execute(\"SELECT MAX(InvoiceLineId) FROM InvoiceLine\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        invoice_line_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO InvoiceLine (InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", invoice_line_id, invoice_id, track_id, unit_price, quantity)\n",
    "        invoice_line_ids.append(invoice_line_id)\n",
    "    return invoice_line_ids\n",
    "\n",
    "def insert_playlists(cursor, num_records):\n",
    "    print(f\"Inserting {num_records} playlists...\")\n",
    "    faker = Faker()\n",
    "    playlist_ids = []\n",
    "    for _ in range(num_records):\n",
    "        name = truncate_string(faker.sentence(nb_words=2), 120)  # NVARCHAR(120)\n",
    "        cursor.execute(\"SELECT MAX(PlaylistId) FROM Playlist\")\n",
    "        max_id_row = cursor.fetchone()\n",
    "        playlist_id = (max_id_row[0] or 0) + 1\n",
    "        cursor.execute(\"INSERT INTO Playlist (PlaylistId, Name) VALUES (?, ?)\", playlist_id, name)\n",
    "        playlist_ids.append(playlist_id)\n",
    "    return playlist_ids\n",
    "\n",
    "def insert_playlisttracks(cursor, playlist_ids, track_ids, num_records):\n",
    "    print(f\"Inserting {num_records} playlist tracks...\")\n",
    "    for _ in range(num_records):\n",
    "        playlist_id = random.choice(playlist_ids)\n",
    "        track_id = random.choice(track_ids)\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM PlaylistTrack WHERE PlaylistId = ? AND TrackId = ?\n",
    "        \"\"\", playlist_id, track_id)\n",
    "        exists = cursor.fetchone()[0]\n",
    "        if not exists:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO PlaylistTrack (PlaylistId, TrackId)\n",
    "                VALUES (?, ?)\n",
    "            \"\"\", playlist_id, track_id)\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    source_server = 'DPC2023'  # Replace with your server name\n",
    "    source_database = 'Chinook'\n",
    "    \n",
    "    # Connect to source database\n",
    "    source_conn = connect_to_db(source_server, source_database)\n",
    "    source_cursor = source_conn.cursor()\n",
    "    \n",
    "    # Start transaction\n",
    "    source_conn.autocommit = False\n",
    "    try:\n",
    "        # Insert data\n",
    "        artist_ids = insert_artists(source_cursor, num_records=10)\n",
    "        genre_ids = insert_genres(source_cursor, num_records=5)\n",
    "        mediatype_ids = insert_mediatypes(source_cursor, num_records=3)\n",
    "        album_ids = insert_albums(source_cursor, artist_ids, num_records=20)\n",
    "        track_ids = insert_tracks(source_cursor, album_ids, genre_ids, mediatype_ids, num_records=50)\n",
    "        employee_ids = insert_employees(source_cursor, num_records=5)\n",
    "        customer_ids = insert_customers(source_cursor, employee_ids, num_records=15)\n",
    "        invoice_ids = insert_invoices(source_cursor, customer_ids, num_records=30)\n",
    "        insert_invoicelines(source_cursor, invoice_ids, track_ids, num_records=100)\n",
    "        playlist_ids = insert_playlists(source_cursor, num_records=5)\n",
    "        insert_playlisttracks(source_cursor, playlist_ids, track_ids, num_records=50)\n",
    "        \n",
    "        # Commit transaction\n",
    "        source_conn.commit()\n",
    "        print(\"Data insertion completed successfully.\")\n",
    "    except Exception as e:\n",
    "        # Rollback transaction on error\n",
    "        source_conn.rollback()\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close connections\n",
    "        source_cursor.close()\n",
    "        source_conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating staging tables if they do not exist...\n",
      "Staging tables created or verified.\n",
      "Truncating staging tables...\n",
      "Staging tables truncated.\n",
      "Preprocessing Artist data...\n",
      "Artist data preprocessed and loaded into staging.\n",
      "Preprocessing Album data...\n",
      "Album data preprocessed and loaded into staging.\n",
      "Preprocessing Genre data...\n",
      "Genre data preprocessed and loaded into staging.\n",
      "Preprocessing MediaType data...\n",
      "MediaType data preprocessed and loaded into staging.\n",
      "Preprocessing Track data...\n",
      "Track data preprocessed and loaded into staging.\n",
      "Preprocessing Employee data...\n",
      "Employee data preprocessed and loaded into staging.\n",
      "Preprocessing Customer data...\n",
      "Customer data preprocessed and loaded into staging.\n",
      "Preprocessing Invoice data...\n",
      "Invoice data preprocessed and loaded into staging.\n",
      "Preprocessing InvoiceLine data...\n",
      "InvoiceLine data preprocessed and loaded into staging.\n",
      "Data preprocessing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def create_staging_tables(target_cursor, target_conn):\n",
    "    print(\"Creating staging tables if they do not exist...\")\n",
    "    staging_tables_sql = [\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Artist', 'U') IS NULL\n",
    "        CREATE TABLE stg_Artist (\n",
    "            ArtistId INT PRIMARY KEY,\n",
    "            Name NVARCHAR(120)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Album', 'U') IS NULL\n",
    "        CREATE TABLE stg_Album (\n",
    "            AlbumId INT PRIMARY KEY,\n",
    "            Title NVARCHAR(160),\n",
    "            ArtistId INT\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Genre', 'U') IS NULL\n",
    "        CREATE TABLE stg_Genre (\n",
    "            GenreId INT PRIMARY KEY,\n",
    "            Name NVARCHAR(120)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_MediaType', 'U') IS NULL\n",
    "        CREATE TABLE stg_MediaType (\n",
    "            MediaTypeId INT PRIMARY KEY,\n",
    "            Name NVARCHAR(120)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Track', 'U') IS NULL\n",
    "        CREATE TABLE stg_Track (\n",
    "            TrackId INT PRIMARY KEY,\n",
    "            Name NVARCHAR(200),\n",
    "            AlbumId INT,\n",
    "            MediaTypeId INT,\n",
    "            GenreId INT,\n",
    "            Composer NVARCHAR(220),\n",
    "            Milliseconds INT,\n",
    "            Bytes INT,\n",
    "            UnitPrice NUMERIC(10,2)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Employee', 'U') IS NULL\n",
    "        CREATE TABLE stg_Employee (\n",
    "            EmployeeId INT PRIMARY KEY,\n",
    "            LastName NVARCHAR(20),\n",
    "            FirstName NVARCHAR(20),\n",
    "            Title NVARCHAR(30),\n",
    "            ReportsTo INT,\n",
    "            BirthDate DATETIME,\n",
    "            HireDate DATETIME,\n",
    "            Address NVARCHAR(70),\n",
    "            City NVARCHAR(40),\n",
    "            State NVARCHAR(40),\n",
    "            Country NVARCHAR(40),\n",
    "            PostalCode NVARCHAR(10),\n",
    "            Phone NVARCHAR(24),\n",
    "            Fax NVARCHAR(24),\n",
    "            Email NVARCHAR(60)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Customer', 'U') IS NULL\n",
    "        CREATE TABLE stg_Customer (\n",
    "            CustomerId INT PRIMARY KEY,\n",
    "            FirstName NVARCHAR(40),\n",
    "            LastName NVARCHAR(20),\n",
    "            Company NVARCHAR(80),\n",
    "            Address NVARCHAR(70),\n",
    "            City NVARCHAR(40),\n",
    "            State NVARCHAR(40),\n",
    "            Country NVARCHAR(40),\n",
    "            PostalCode NVARCHAR(10),\n",
    "            Phone NVARCHAR(24),\n",
    "            Fax NVARCHAR(24),\n",
    "            Email NVARCHAR(60),\n",
    "            SupportRepId INT\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_Invoice', 'U') IS NULL\n",
    "        CREATE TABLE stg_Invoice (\n",
    "            InvoiceId INT PRIMARY KEY,\n",
    "            CustomerId INT,\n",
    "            InvoiceDate DATETIME,\n",
    "            BillingAddress NVARCHAR(70),\n",
    "            BillingCity NVARCHAR(40),\n",
    "            BillingState NVARCHAR(40),\n",
    "            BillingCountry NVARCHAR(40),\n",
    "            BillingPostalCode NVARCHAR(10),\n",
    "            Total NUMERIC(10,2)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        IF OBJECT_ID('stg_InvoiceLine', 'U') IS NULL\n",
    "        CREATE TABLE stg_InvoiceLine (\n",
    "            InvoiceLineId INT PRIMARY KEY,\n",
    "            InvoiceId INT,\n",
    "            TrackId INT,\n",
    "            UnitPrice NUMERIC(10,2),\n",
    "            Quantity INT\n",
    "        )\n",
    "        \"\"\"\n",
    "    ]\n",
    "    for sql in staging_tables_sql:\n",
    "        target_cursor.execute(sql)\n",
    "    target_conn.commit()\n",
    "    print(\"Staging tables created or verified.\")\n",
    "\n",
    "def truncate_staging_tables(target_cursor, target_conn):\n",
    "    print(\"Truncating staging tables...\")\n",
    "    tables = ['stg_Artist', 'stg_Album', 'stg_Genre', 'stg_MediaType', 'stg_Track', 'stg_Employee', 'stg_Customer', 'stg_Invoice', 'stg_InvoiceLine']\n",
    "    for table in tables:\n",
    "        target_cursor.execute(f\"TRUNCATE TABLE {table}\")\n",
    "    target_conn.commit()\n",
    "    print(\"Staging tables truncated.\")\n",
    "\n",
    "def preprocess_artist(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Artist data...\")\n",
    "    source_cursor.execute(\"SELECT ArtistId, Name FROM Artist\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        # Data Cleaning: Standardize names\n",
    "        name = row.Name.strip().title() if row.Name else None\n",
    "        target_cursor.execute(\"INSERT INTO stg_Artist (ArtistId, Name) VALUES (?, ?)\", row.ArtistId, name)\n",
    "    print(\"Artist data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_album(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Album data...\")\n",
    "    source_cursor.execute(\"SELECT AlbumId, Title, ArtistId FROM Album\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        title = row.Title.strip().title() if row.Title else None\n",
    "        target_cursor.execute(\"INSERT INTO stg_Album (AlbumId, Title, ArtistId) VALUES (?, ?, ?)\", row.AlbumId, title, row.ArtistId)\n",
    "    print(\"Album data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_genre(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Genre data...\")\n",
    "    source_cursor.execute(\"SELECT GenreId, Name FROM Genre\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        name = row.Name.strip().title() if row.Name else None\n",
    "        target_cursor.execute(\"INSERT INTO stg_Genre (GenreId, Name) VALUES (?, ?)\", row.GenreId, name)\n",
    "    print(\"Genre data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_mediatype(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing MediaType data...\")\n",
    "    source_cursor.execute(\"SELECT MediaTypeId, Name FROM MediaType\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        name = row.Name.strip().title() if row.Name else None\n",
    "        target_cursor.execute(\"INSERT INTO stg_MediaType (MediaTypeId, Name) VALUES (?, ?)\", row.MediaTypeId, name)\n",
    "    print(\"MediaType data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_track(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Track data...\")\n",
    "    source_cursor.execute(\"SELECT TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice FROM Track\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        name = row.Name.strip().title() if row.Name else None\n",
    "        composer = row.Composer.strip().title() if row.Composer else None\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO stg_Track (TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.TrackId, name, row.AlbumId, row.MediaTypeId, row.GenreId, composer, row.Milliseconds, row.Bytes, row.UnitPrice)\n",
    "    print(\"Track data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_employee(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Employee data...\")\n",
    "    source_cursor.execute(\"\"\"\n",
    "        SELECT EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate,\n",
    "               Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
    "        FROM Employee\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        # Data Cleaning: Standardize names and addresses\n",
    "        last_name = row.LastName.strip().title() if row.LastName else None\n",
    "        first_name = row.FirstName.strip().title() if row.FirstName else None\n",
    "        title = row.Title.strip().title() if row.Title else None\n",
    "        address = row.Address.strip().title() if row.Address else None\n",
    "        city = row.City.strip().title() if row.City else None\n",
    "        state = row.State.strip().title() if row.State else None\n",
    "        country = row.Country.strip().title() if row.Country else None\n",
    "        email = row.Email.strip().lower() if row.Email else None\n",
    "        # Data Transformation: Validate email format\n",
    "        email = email if re.match(r\"[^@]+@[^@]+\\.[^@]+\", email) else None\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO stg_Employee (EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate,\n",
    "                                      Address, City, State, Country, PostalCode, Phone, Fax, Email)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.EmployeeId, last_name, first_name, title, row.ReportsTo, row.BirthDate, row.HireDate,\n",
    "             address, city, state, country, row.PostalCode, row.Phone, row.Fax, email)\n",
    "    print(\"Employee data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_customer(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Customer data...\")\n",
    "    source_cursor.execute(\"\"\"\n",
    "        SELECT CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode,\n",
    "               Phone, Fax, Email, SupportRepId\n",
    "        FROM Customer\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        first_name = row.FirstName.strip().title() if row.FirstName else None\n",
    "        last_name = row.LastName.strip().title() if row.LastName else None\n",
    "        company = row.Company.strip().title() if row.Company else None\n",
    "        address = row.Address.strip().title() if row.Address else None\n",
    "        city = row.City.strip().title() if row.City else None\n",
    "        state = row.State.strip().title() if row.State else None\n",
    "        country = row.Country.strip().title() if row.Country else None\n",
    "        email = row.Email.strip().lower() if row.Email else None\n",
    "        # Data Transformation: Validate email format\n",
    "        email = email if re.match(r\"[^@]+@[^@]+\\.[^@]+\", email) else None\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO stg_Customer (CustomerId, FirstName, LastName, Company, Address, City, State,\n",
    "                                      Country, PostalCode, Phone, Fax, Email, SupportRepId)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.CustomerId, first_name, last_name, company, address, city, state,\n",
    "             country, row.PostalCode, row.Phone, row.Fax, email, row.SupportRepId)\n",
    "    print(\"Customer data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_invoice(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing Invoice data...\")\n",
    "    source_cursor.execute(\"\"\"\n",
    "        SELECT InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState,\n",
    "               BillingCountry, BillingPostalCode, Total\n",
    "        FROM Invoice\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        billing_address = row.BillingAddress.strip().title() if row.BillingAddress else None\n",
    "        billing_city = row.BillingCity.strip().title() if row.BillingCity else None\n",
    "        billing_state = row.BillingState.strip().title() if row.BillingState else None\n",
    "        billing_country = row.BillingCountry.strip().title() if row.BillingCountry else None\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO stg_Invoice (InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity,\n",
    "                                     BillingState, BillingCountry, BillingPostalCode, Total)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.InvoiceId, row.CustomerId, row.InvoiceDate, billing_address, billing_city,\n",
    "             billing_state, billing_country, row.BillingPostalCode, row.Total)\n",
    "    print(\"Invoice data preprocessed and loaded into staging.\")\n",
    "\n",
    "def preprocess_invoiceline(source_cursor, target_cursor):\n",
    "    print(\"Preprocessing InvoiceLine data...\")\n",
    "    source_cursor.execute(\"\"\"\n",
    "        SELECT InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
    "        FROM InvoiceLine\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    for row in rows:\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO stg_InvoiceLine (InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", row.InvoiceLineId, row.InvoiceId, row.TrackId, row.UnitPrice, row.Quantity)\n",
    "    print(\"InvoiceLine data preprocessed and loaded into staging.\")\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    source_server = 'DPC2023'   # Replace with your source server name\n",
    "    source_database = 'Chinook'\n",
    "    target_server = 'DPC2023'   # Replace with your target server name\n",
    "    target_database = 'ChinookDW4'\n",
    "\n",
    "    # Connect to source and target databases\n",
    "    source_conn = connect_to_db(source_server, source_database)\n",
    "    target_conn = connect_to_db(target_server, target_database)\n",
    "\n",
    "    source_cursor = source_conn.cursor()\n",
    "    target_cursor = target_conn.cursor()\n",
    "\n",
    "    # Create staging tables if they do not exist\n",
    "    create_staging_tables(target_cursor, target_conn)\n",
    "\n",
    "    # Truncate staging tables\n",
    "    truncate_staging_tables(target_cursor, target_conn)\n",
    "\n",
    "    # Preprocess and load data into staging tables\n",
    "    preprocess_artist(source_cursor, target_cursor)\n",
    "    preprocess_album(source_cursor, target_cursor)\n",
    "    preprocess_genre(source_cursor, target_cursor)\n",
    "    preprocess_mediatype(source_cursor, target_cursor)\n",
    "    preprocess_track(source_cursor, target_cursor)\n",
    "    preprocess_employee(source_cursor, target_cursor)\n",
    "    preprocess_customer(source_cursor, target_cursor)\n",
    "    preprocess_invoice(source_cursor, target_cursor)\n",
    "    preprocess_invoiceline(source_cursor, target_cursor)\n",
    "\n",
    "    # Commit changes\n",
    "    target_conn.commit()\n",
    "\n",
    "    # Close connections\n",
    "    source_cursor.close()\n",
    "    target_cursor.close()\n",
    "    source_conn.close()\n",
    "    target_conn.close()\n",
    "    print(\"Data preprocessing completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DimArtist...\n",
      "DimArtist loaded. 600 new records inserted.\n",
      "Loading DimAlbum...\n",
      "DimAlbum loaded. 1200 new records inserted.\n",
      "Loading DimGenre...\n",
      "DimGenre loaded. 300 new records inserted.\n",
      "Loading DimMediaType...\n",
      "DimMediaType loaded. 180 new records inserted.\n",
      "Loading DimTrack...\n",
      "DimTrack loaded. 3000 new records inserted.\n",
      "Loading DimEmployee...\n",
      "DimEmployee loaded. 300 new records inserted.\n",
      "Loading DimCustomer...\n",
      "DimCustomer loaded. 900 new records inserted.\n",
      "Loading DimDate...\n",
      "DimDate loaded. 857 new records inserted.\n",
      "Building mappings from natural keys to surrogate keys...\n",
      "Mappings built.\n",
      "Loading FactSales...\n",
      "FactSales loaded. 6000 new records inserted.\n",
      "ETL process completed.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='etl_log.log', level=logging.INFO, \n",
    "                    format='%(asctime)s %(levelname)s:%(message)s')\n",
    "\n",
    "logging.info('ETL process started.')\n",
    "\n",
    "def truncate_tables(target_cursor, target_conn):\n",
    "    print(\"Deleting data from Dimension and Fact Tables...\")\n",
    "    tables = ['FactSales', 'DimCustomer', 'DimEmployee', 'DimDate', 'DimTrack', 'DimMediaType', 'DimGenre', 'DimAlbum', 'DimArtist']\n",
    "    for table in tables:\n",
    "        target_cursor.execute(f\"DELETE FROM {table}\")\n",
    "        print(f\"Data deleted from table {table}.\")\n",
    "    target_conn.commit()\n",
    "\n",
    "def load_dim_artist(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimArtist...\")\n",
    "    # Fetch existing ArtistIds\n",
    "    target_cursor.execute(\"SELECT ArtistId FROM DimArtist\")\n",
    "    existing_artist_ids = set(row.ArtistId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT ArtistId, Name FROM Artist\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.ArtistId not in existing_artist_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"INSERT INTO DimArtist (ArtistId, Name) VALUES (?, ?)\", row.ArtistId, row.Name)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimArtist loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_album(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimAlbum...\")\n",
    "    # Fetch existing AlbumIds\n",
    "    target_cursor.execute(\"SELECT AlbumId FROM DimAlbum\")\n",
    "    existing_album_ids = set(row.AlbumId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT AlbumId, Title, ArtistId FROM Album\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.AlbumId not in existing_album_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"SELECT ArtistKey FROM DimArtist WHERE ArtistId = ?\", row.ArtistId)\n",
    "        artist_key_row = target_cursor.fetchone()\n",
    "        artist_key = artist_key_row.ArtistKey if artist_key_row else None\n",
    "        target_cursor.execute(\"INSERT INTO DimAlbum (AlbumId, Title, ArtistKey) VALUES (?, ?, ?)\", row.AlbumId, row.Title, artist_key)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimAlbum loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_genre(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimGenre...\")\n",
    "    # Fetch existing GenreIds\n",
    "    target_cursor.execute(\"SELECT GenreId FROM DimGenre\")\n",
    "    existing_genre_ids = set(row.GenreId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT GenreId, Name FROM Genre\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.GenreId not in existing_genre_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"INSERT INTO DimGenre (GenreId, Name) VALUES (?, ?)\", row.GenreId, row.Name)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimGenre loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_mediatype(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimMediaType...\")\n",
    "    # Fetch existing MediaTypeIds\n",
    "    target_cursor.execute(\"SELECT MediaTypeId FROM DimMediaType\")\n",
    "    existing_mediatype_ids = set(row.MediaTypeId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT MediaTypeId, Name FROM MediaType\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.MediaTypeId not in existing_mediatype_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"INSERT INTO DimMediaType (MediaTypeId, Name) VALUES (?, ?)\", row.MediaTypeId, row.Name)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimMediaType loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_track(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimTrack...\")\n",
    "    # Fetch existing TrackIds\n",
    "    target_cursor.execute(\"SELECT TrackId FROM DimTrack\")\n",
    "    existing_track_ids = set(row.TrackId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes FROM Track\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.TrackId not in existing_track_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        # Get AlbumKey\n",
    "        target_cursor.execute(\"SELECT AlbumKey FROM DimAlbum WHERE AlbumId = ?\", row.AlbumId)\n",
    "        album_key_row = target_cursor.fetchone()\n",
    "        album_key = album_key_row.AlbumKey if album_key_row else None\n",
    "\n",
    "        # Get MediaTypeKey\n",
    "        target_cursor.execute(\"SELECT MediaTypeKey FROM DimMediaType WHERE MediaTypeId = ?\", row.MediaTypeId)\n",
    "        mediatype_key_row = target_cursor.fetchone()\n",
    "        mediatype_key = mediatype_key_row.MediaTypeKey if mediatype_key_row else None\n",
    "\n",
    "        # Get GenreKey\n",
    "        target_cursor.execute(\"SELECT GenreKey FROM DimGenre WHERE GenreId = ?\", row.GenreId)\n",
    "        genre_key_row = target_cursor.fetchone()\n",
    "        genre_key = genre_key_row.GenreKey if genre_key_row else None\n",
    "\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO DimTrack (TrackId, Name, AlbumKey, MediaTypeKey, GenreKey, Composer, Milliseconds, Bytes)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", row.TrackId, row.Name, album_key, mediatype_key, genre_key, row.Composer, row.Milliseconds, row.Bytes)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimTrack loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_employee(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimEmployee...\")\n",
    "    # Fetch existing EmployeeIds\n",
    "    target_cursor.execute(\"SELECT EmployeeId FROM DimEmployee\")\n",
    "    existing_employee_ids = set(row.EmployeeId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT EmployeeId, FirstName, LastName, Title, ReportsTo, HireDate FROM Employee\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.EmployeeId not in existing_employee_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO DimEmployee (EmployeeId, FirstName, LastName, Title, ReportsTo, HireDate)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.EmployeeId, row.FirstName, row.LastName, row.Title, row.ReportsTo, row.HireDate)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimEmployee loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_customer(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimCustomer...\")\n",
    "    # Fetch existing CustomerIds\n",
    "    target_cursor.execute(\"SELECT CustomerId FROM DimCustomer\")\n",
    "    existing_customer_ids = set(row.CustomerId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"\"\"\n",
    "        SELECT CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode\n",
    "        FROM Customer\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.CustomerId not in existing_customer_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO DimCustomer (CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row.CustomerId, row.FirstName, row.LastName, row.Company, row.Address, row.City, row.State, row.Country, row.PostalCode)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimCustomer loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def load_dim_date(source_cursor, target_cursor, target_conn):\n",
    "    print(\"Loading DimDate...\")\n",
    "    # Fetch existing Dates\n",
    "    target_cursor.execute(\"SELECT Date FROM DimDate\")\n",
    "    existing_dates = set(row.Date for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"SELECT DISTINCT CAST(InvoiceDate AS DATE) AS Date FROM Invoice\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.Date not in existing_dates]\n",
    "\n",
    "    for row in new_rows:\n",
    "        date_value = row.Date\n",
    "        day = date_value.day\n",
    "        month = date_value.month\n",
    "        year = date_value.year\n",
    "        quarter = (month - 1) // 3 + 1\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO DimDate (Date, Day, Month, Year, Quarter)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", date_value, day, month, year, quarter)\n",
    "    target_conn.commit()\n",
    "    print(f\"DimDate loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def build_mappings(target_cursor):\n",
    "    print(\"Building mappings from natural keys to surrogate keys...\")\n",
    "    mappings = {}\n",
    "\n",
    "    # ArtistId to ArtistKey\n",
    "    target_cursor.execute(\"SELECT ArtistId, ArtistKey FROM DimArtist\")\n",
    "    mappings['Artist'] = {row.ArtistId: row.ArtistKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # AlbumId to AlbumKey\n",
    "    target_cursor.execute(\"SELECT AlbumId, AlbumKey FROM DimAlbum\")\n",
    "    mappings['Album'] = {row.AlbumId: row.AlbumKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # GenreId to GenreKey\n",
    "    target_cursor.execute(\"SELECT GenreId, GenreKey FROM DimGenre\")\n",
    "    mappings['Genre'] = {row.GenreId: row.GenreKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # MediaTypeId to MediaTypeKey\n",
    "    target_cursor.execute(\"SELECT MediaTypeId, MediaTypeKey FROM DimMediaType\")\n",
    "    mappings['MediaType'] = {row.MediaTypeId: row.MediaTypeKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # TrackId to TrackKey\n",
    "    target_cursor.execute(\"SELECT TrackId, TrackKey FROM DimTrack\")\n",
    "    mappings['Track'] = {row.TrackId: row.TrackKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # Date to DateKey\n",
    "    target_cursor.execute(\"SELECT Date, DateKey FROM DimDate\")\n",
    "    mappings['Date'] = {row.Date: row.DateKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # CustomerId to CustomerKey\n",
    "    target_cursor.execute(\"SELECT CustomerId, CustomerKey FROM DimCustomer\")\n",
    "    mappings['Customer'] = {row.CustomerId: row.CustomerKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    # EmployeeId to EmployeeKey\n",
    "    target_cursor.execute(\"SELECT EmployeeId, EmployeeKey FROM DimEmployee\")\n",
    "    mappings['Employee'] = {row.EmployeeId: row.EmployeeKey for row in target_cursor.fetchall()}\n",
    "\n",
    "    print(\"Mappings built.\")\n",
    "    return mappings\n",
    "\n",
    "def load_fact_sales(source_cursor, target_cursor, target_conn, mappings):\n",
    "    print(\"Loading FactSales...\")\n",
    "    # Fetch existing InvoiceLineIds\n",
    "    target_cursor.execute(\"SELECT InvoiceLineId FROM FactSales\")\n",
    "    existing_invoice_line_ids = set(row.InvoiceLineId for row in target_cursor.fetchall())\n",
    "\n",
    "    source_cursor.execute(\"\"\"\n",
    "    SELECT il.InvoiceLineId, il.InvoiceId, il.TrackId, il.Quantity, il.UnitPrice,\n",
    "           i.InvoiceDate, i.CustomerId,\n",
    "           t.AlbumId, t.GenreId, t.MediaTypeId,\n",
    "           c.SupportRepId\n",
    "    FROM InvoiceLine il\n",
    "    JOIN Invoice i ON il.InvoiceId = i.InvoiceId\n",
    "    JOIN Track t ON il.TrackId = t.TrackId\n",
    "    JOIN Customer c ON i.CustomerId = c.CustomerId\n",
    "    \"\"\")\n",
    "    rows = source_cursor.fetchall()\n",
    "    new_rows = [row for row in rows if row.InvoiceLineId not in existing_invoice_line_ids]\n",
    "\n",
    "    for row in new_rows:\n",
    "        InvoiceLineId = row.InvoiceLineId\n",
    "        InvoiceDate = row.InvoiceDate.date()\n",
    "        DateKey = mappings['Date'].get(InvoiceDate, None)\n",
    "        CustomerKey = mappings['Customer'].get(row.CustomerId, None)\n",
    "        TrackKey = mappings['Track'].get(row.TrackId, None)\n",
    "        AlbumKey = mappings['Album'].get(row.AlbumId, None)\n",
    "        GenreKey = mappings['Genre'].get(row.GenreId, None)\n",
    "        MediaTypeKey = mappings['MediaType'].get(row.MediaTypeId, None)\n",
    "        EmployeeKey = mappings['Employee'].get(row.SupportRepId, None)\n",
    "        Quantity = row.Quantity\n",
    "        UnitPrice = row.UnitPrice\n",
    "        TotalAmount = Quantity * UnitPrice\n",
    "\n",
    "        target_cursor.execute(\"\"\"\n",
    "            INSERT INTO FactSales (InvoiceLineId, DateKey, CustomerKey, TrackKey, AlbumKey, GenreKey, MediaTypeKey, EmployeeKey, Quantity, UnitPrice, TotalAmount)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", InvoiceLineId, DateKey, CustomerKey, TrackKey, AlbumKey, GenreKey, MediaTypeKey, EmployeeKey, Quantity, UnitPrice, TotalAmount)\n",
    "    target_conn.commit()\n",
    "    print(f\"FactSales loaded. {len(new_rows)} new records inserted.\")\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    source_server = 'DPC2023'\n",
    "    source_database = 'Chinook'\n",
    "    target_server = 'DPC2023'\n",
    "    target_database = 'ChinookDW4'\n",
    "\n",
    "    # Connect to source and target databases\n",
    "    source_conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+source_server+';DATABASE='+source_database+';Trusted_Connection=yes;')\n",
    "    target_conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+target_server+';DATABASE='+target_database+';Trusted_Connection=yes;')\n",
    "\n",
    "    source_cursor = source_conn.cursor()\n",
    "    target_cursor = target_conn.cursor()\n",
    "\n",
    "    # Prompt user to reset DW\n",
    "    reset_dw = input(\"Do you want to reset the Data Warehouse? (yes/no): \").lower()\n",
    "    if reset_dw == 'yes':\n",
    "        truncate_tables(target_cursor, target_conn)\n",
    "\n",
    "    # Load dimension tables\n",
    "    load_dim_artist(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_album(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_genre(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_mediatype(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_track(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_employee(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_customer(source_cursor, target_cursor, target_conn)\n",
    "    load_dim_date(source_cursor, target_cursor, target_conn)\n",
    "\n",
    "    # Build mappings\n",
    "    mappings = build_mappings(target_cursor)\n",
    "\n",
    "    # Load FactSales\n",
    "    load_fact_sales(source_cursor, target_cursor, target_conn, mappings)\n",
    "\n",
    "    # Close connections\n",
    "    source_cursor.close()\n",
    "    target_cursor.close()\n",
    "    source_conn.close()\n",
    "    target_conn.close()\n",
    "    print(\"ETL process completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    logging.info('ETL process completed successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\2380870178.py:39: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           12
          ],
          [
           12
          ],
          [
           9
          ],
          [
           12
          ],
          [
           11
          ],
          [
           9
          ],
          [
           8
          ],
          [
           9
          ],
          [
           10
          ],
          [
           7
          ],
          [
           9
          ],
          [
           8
          ],
          [
           8
          ],
          [
           9
          ],
          [
           9
          ],
          [
           7
          ],
          [
           8
          ],
          [
           6
          ],
          [
           8
          ],
          [
           6
          ],
          [
           6
          ],
          [
           7
          ],
          [
           9
          ],
          [
           6
          ],
          [
           9
          ],
          [
           6
          ],
          [
           7
          ],
          [
           6
          ],
          [
           6
          ],
          [
           6
          ],
          [
           9
          ],
          [
           5
          ],
          [
           5
          ],
          [
           6
          ],
          [
           4
          ],
          [
           8
          ],
          [
           8
          ],
          [
           8
          ],
          [
           4
          ],
          [
           6
          ],
          [
           5
          ],
          [
           7
          ],
          [
           7
          ],
          [
           7
          ],
          [
           5
          ],
          [
           4
          ],
          [
           5
          ],
          [
           6
          ],
          [
           3
          ],
          [
           6
          ],
          [
           6
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           3
          ],
          [
           3
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           4
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           3
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           2
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ],
          [
           1
          ]
         ],
         "hovertemplate": "Revenue (USD)=%{x}<br>Album Title=%{y}<br>QuantitySold=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          21.15,
          20.48,
          17.91,
          17.24,
          17.02,
          15.93,
          15.82,
          15.4,
          15.05,
          13.93,
          13.08,
          13.04,
          12.82,
          12.56,
          12.37,
          11.9,
          11.6,
          11.38,
          11.12,
          10.88,
          10.87,
          10.82,
          10.71,
          10.35,
          10.33,
          10.22,
          10.14,
          9.88,
          9.36,
          9.26,
          8.91,
          8.85,
          8.7,
          8.32,
          7.96,
          7.92,
          7.92,
          7.92,
          7.72,
          7.18,
          7.14,
          6.93,
          6.93,
          6.93,
          6.85,
          6.66,
          6.4,
          6.4,
          5.97,
          5.94,
          5.94,
          5.6,
          5.15,
          4.95,
          4.95,
          4.95,
          4.95,
          4.95,
          4.95,
          4.95,
          4.95,
          4.95,
          4.41,
          3.99,
          3.98,
          3.98,
          3.98,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.96,
          3.64,
          3.54,
          3.2,
          3.1,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.97,
          2.64,
          2.53,
          2.48,
          1.99,
          1.99,
          1.99,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.98,
          1.32,
          1.26,
          1.23,
          1.19,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99,
          0.99
         ],
         "xaxis": "x",
         "y": [
          "Certainly computer.",
          "Success.",
          "Battlestar Galactica (Classic), Season 1",
          "Admit during admit.",
          "Bill past official.",
          "Upon day message.",
          "Ahead career standard.",
          "Could threat its.",
          "Sign name.",
          "Lost, Season 2",
          "Site never.",
          "Ahead add.",
          "Wife.",
          "Glass eight ten.",
          "Morning rather.",
          "Prepare future wide.",
          "Stay put fund.",
          "Young PM.",
          "Test.",
          "Media game just.",
          "Eight federal include.",
          "None whole.",
          "Administration I.",
          "Head where.",
          "Cause church.",
          "Decide usually.",
          "Officer small.",
          "Second hundred.",
          "Citizen.",
          "Same structure left.",
          "Unplugged",
          "Loss wonder.",
          "Form.",
          "Clearly country budget serve.",
          "Heroes, Season 1",
          "Vinícius De Moraes - Sem Limite",
          "New Adventures In Hi-Fi",
          "Rattle And Hum",
          "Center notice.",
          "Edge scientist.",
          "Race.",
          "Elis Regina-Minha História",
          "Greatest Hits II",
          "Back to Black",
          "Truth card tell visit.",
          "Agent rate debate.",
          "Behavior performance begin.",
          "Life there.",
          "Battlestar Galactica, Season 3",
          "Arquivo II",
          "Chemical Wedding",
          "Security understand trouble.",
          "Turn forward.",
          "Serie Sem Limite (Disc 1)",
          "Serie Sem Limite (Disc 2)",
          "The Cream Of Clapton",
          "Prenda Minha",
          "Acústico",
          "Instant Karma: The Amnesty International Campaign to Save Darfur",
          "Minha Historia",
          "Greatest Kiss",
          "In Step",
          "Specific among.",
          "Son industry he.",
          "The Office, Season 2",
          "The Office, Season 3",
          "LOST, Season 4",
          "Morning Dance",
          "Greatest Hits",
          "Frank",
          "Faceless",
          "Afrociberdelia",
          "Arquivo Os Paralamas Do Sucesso",
          "Chronicle, Vol. 1",
          "Vozes do MPB",
          "The Best Of R.E.M.: The IRS Years",
          "The Best Of 1980-1990",
          "The Best Of Buddy Guy - The Millenium Collection",
          "Kid run.",
          "End training.",
          "Film responsibility.",
          "Past behind.",
          "Original Soundtracks 1",
          "Raul Seixas",
          "The Best Of Van Halen, Vol. I",
          "Volume Dois",
          "The Singles",
          "Use Your Illusion II",
          "Garage Inc. (Disc 1)",
          "House of Pain",
          "International Superhits",
          "Live On Two Legs [Live]",
          "My Way: The Best Of Frank Sinatra [Disc 1]",
          "Chronicle, Vol. 2",
          "Core",
          "Cássia Eller - Coleção Sem Limite [Disc 2]",
          "By The Way",
          "American Idiot",
          "Angel Dust",
          "Ao Vivo [IMPORT]",
          "Appetite for Destruction",
          "Gun situation.",
          "Say eight religious.",
          "Rate within recently together.",
          "The Office, Season 1",
          "Lost, Season 3",
          "Lost, Season 1",
          "Live [Disc 2]",
          "Hot Rocks, 1964-1971 (Disc 1)",
          "In Your Honor [Disc 2]",
          "Into The Light",
          "Jagged Little Pill",
          "Judas 0: B-Sides and Rarities",
          "King For A Day Fool For A Lifetime",
          "Meus Momentos",
          "Mezmerize",
          "Maquinarama",
          "Greatest Hits I",
          "Heart of the Night",
          "For Those About To Rock We Salute You",
          "Facelift",
          "Diver Down",
          "BBC Sessions [Disc 1] [Live]",
          "Audioslave",
          "Album Of The Year",
          "Alcohol Fueled Brewtality Live! [Disc 1]",
          "Acústico MTV",
          "Acústico MTV [Live]",
          "[1997] Black Light Syndrome",
          "20th Century Masters - The Millennium Collection: The Best of Scorpions",
          "Californication",
          "Cássia Eller - Sem Limite [Disc 1]",
          "B-Sides 1980-1990",
          "Beyond Good And Evil",
          "Big Ones",
          "Blood Sugar Sex Magik",
          "Blue Moods",
          "Carry On",
          "Da Lama Ao Caos",
          "Cidade Negra - Hits",
          "Chill: Brazil (Disc 1)",
          "Chill: Brazil (Disc 2)",
          "The Essential Miles Davis [Disc 1]",
          "Tangents",
          "Speak of the Devil",
          "Supernatural",
          "Quanta Gente Veio Ver (Live)",
          "Radio Brasil (O Som da Jovem Vanguarda) - Seleccao de Henrique Amaro",
          "My Generation - The Very Best Of The Who",
          "Pure Cult: The Best Of The Cult (For Rockers, Ravers, Lovers & Sinners) [UK]",
          "Riot Act",
          "Roda De Funk",
          "Rotten Apples: Greatest Hits",
          "Out Of Time",
          "News Of The World",
          "Use Your Illusion I",
          "Up An' Atom",
          "The Real Thing",
          "Tribute",
          "UB40 The Best Of - Volume Two [UK]",
          "Voodoo Lounge",
          "Van Halen III",
          "Vault: Def Leppard's Greatest Hits",
          "Vinicius De Moraes",
          "Walking Into Clarksdale",
          "War",
          "Zooropa",
          "Seem TV.",
          "Executive enough ever.",
          "Candidate business.",
          "Feel run rather.",
          "Fireball",
          "Djavan Ao Vivo - Vol. 02",
          "Djavan Ao Vivo - Vol. 1",
          "Deep Purple In Rock",
          "Deixa Entrar",
          "Holst: The Planets, Op. 32 & Vaughan Williams: Fantasies",
          "How To Dismantle An Atomic Bomb",
          "In Your Honor [Disc 1]",
          "Górecki: Symphony No. 3",
          "Haydn: Symphonies 99 - 104",
          "Green",
          "Minha História",
          "MK III The Final Concerts [Disc 1]",
          "Na Pista",
          "Muso Ko",
          "Mendelssohn: A Midsummer Night's Dream",
          "Machine Head",
          "Knocking at Your Back Door: The Best Of Deep Purple in the 80's",
          "Let There Be Rock",
          "Live [Disc 1]",
          "Carnaval 2001",
          "Body Count",
          "Bongo Fury",
          "Black Sabbath",
          "Black Sabbath Vol. 4 (Remaster)",
          "Cesta Básica",
          "Dark Side Of The Moon",
          "Come Taste The Band",
          "Contraband",
          "A Matter of Life and Death",
          "Achtung Baby",
          "Adams, John: The Chairman Dances",
          "All That You Can't Leave Behind",
          "Axé Bahia 2001",
          "BackBeat Soundtrack",
          "Balls to the Wall",
          "Bark at the Moon (Remastered)",
          "As Canções de Eu Tu Eles",
          "A-Sides",
          "Scheherazade",
          "Santana - As Years Go By",
          "Santana Live",
          "Szymanowski: Piano Works, Vol. 1",
          "Stormbringer",
          "Slaves And Masters",
          "Temple of the Dog",
          "Ten",
          "The Battle Rages On",
          "The Beast Live",
          "The Best of Ed Motta",
          "The Best Of Billy Cobham",
          "The Essential Miles Davis [Disc 2]",
          "The Colour And The Shape",
          "The Doors",
          "No More Tears (Remastered)",
          "No Security",
          "One By One",
          "O Samba Poconé",
          "Outbreak",
          "Pachelbel: Canon & Gigue",
          "Os Cães Ladram Mas A Caravana Não Pára",
          "Out Of Exile",
          "Pearl Jam",
          "Physical Graffiti [Disc 1]",
          "Plays Metallica By Four Cellos",
          "Pop",
          "Sambas De Enredo 2001",
          "Respighi:Pines of Rome",
          "Retrospective I (1974-1980)",
          "Revelations",
          "Purpendicular",
          "Vs.",
          "Warner 25 Anos",
          "Weill: The Seven Deadly Sins",
          "Un-Led-Ed",
          "Transmission",
          "The Police Greatest Hits",
          "Van Halen"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Album Revenue in 2023"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Revenue (USD)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Album Title"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'ChinookDW4'\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    \n",
    "    # Define the SQL query\n",
    "    sql_query = '''\n",
    "    SELECT \n",
    "        DimAlbum.Title AS AlbumTitle,\n",
    "        SUM(FactSales.Quantity) AS QuantitySold,\n",
    "        SUM(FactSales.TotalAmount) AS Revenue\n",
    "    FROM \n",
    "        FactSales\n",
    "    JOIN \n",
    "        DimAlbum ON FactSales.AlbumKey = DimAlbum.AlbumKey\n",
    "    JOIN \n",
    "        DimDate ON FactSales.DateKey = DimDate.DateKey\n",
    "    WHERE \n",
    "        DimDate.Year = 2023  -- Specify the desired year or date range here\n",
    "    GROUP BY \n",
    "        DimAlbum.Title\n",
    "    ORDER BY \n",
    "        Revenue DESC;  -- Or use `QuantitySold DESC` to sort by quantity sold\n",
    "    '''\n",
    "    \n",
    "    # Fetch data into a pandas DataFrame\n",
    "    df = pd.read_sql(sql_query, conn)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    # Check if data is available\n",
    "    if df.empty:\n",
    "        print(\"No data available for the specified year.\")\n",
    "        return\n",
    "    \n",
    "    # Data visualization using Plotly\n",
    "    fig = px.bar(\n",
    "        df, \n",
    "        x='Revenue', \n",
    "        y='AlbumTitle', \n",
    "        orientation='h',\n",
    "        title='Album Revenue in 2023',\n",
    "        hover_data=['QuantitySold'],\n",
    "        labels={'AlbumTitle': 'Album Title', 'Revenue': 'Revenue (USD)'},\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        yaxis={'categoryorder':'total ascending'},\n",
    "        height=600,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\314312393.py:36: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           13,
           1.058825
          ],
          [
           8,
           0.999868
          ],
          [
           6,
           1.068974
          ],
          [
           5,
           1.026842
          ],
          [
           4,
           2.427727
          ],
          [
           4,
           1.029473
          ],
          [
           3,
           0.99
          ],
          [
           2,
           4.130833
          ],
          [
           2,
           1.187368
          ],
          [
           1,
           4.675882
          ],
          [
           2,
           1.016315
          ],
          [
           2,
           1.017027
          ],
          [
           1,
           4.145555
          ],
          [
           2,
           1.582391
          ],
          [
           2,
           4.542666
          ],
          [
           1,
           3.747222
          ],
          [
           1,
           5.045384
          ],
          [
           2,
           1.435581
          ],
          [
           2,
           1.454634
          ],
          [
           1,
           4.899166
          ],
          [
           1,
           4.898333
          ],
          [
           1,
           4.641666
          ],
          [
           2,
           4.5675
          ],
          [
           1,
           4.473333
          ],
          [
           1,
           4.696363
          ],
          [
           1,
           4.654545
          ],
          [
           1,
           4.24
          ],
          [
           2,
           1.24675
          ],
          [
           1,
           6.09125
          ],
          [
           1,
           4.04
          ],
          [
           1,
           5.111111
          ],
          [
           1,
           1.200526
          ],
          [
           1,
           4.98
          ],
          [
           1,
           4.881111
          ],
          [
           2,
           3.6225
          ],
          [
           1,
           4.785555
          ],
          [
           1,
           3.240769
          ],
          [
           2,
           4.184
          ],
          [
           1,
           1.095263
          ],
          [
           1,
           1.068947
          ],
          [
           1,
           4.056
          ],
          [
           1,
           5.04125
          ],
          [
           1,
           3.964
          ],
          [
           1,
           1.042631
          ],
          [
           1,
           4.39
          ],
          [
           1,
           0.99
          ],
          [
           1,
           0.99
          ],
          [
           1,
           0.99
          ],
          [
           1,
           0.99
          ],
          [
           1,
           0.99
          ],
          [
           1,
           0.99
          ],
          [
           1,
           3.508
          ],
          [
           1,
           4.34
          ],
          [
           1,
           5.756666
          ],
          [
           1,
           4.8
          ],
          [
           1,
           4.655714
          ],
          [
           1,
           4.572857
          ],
          [
           1,
           6.28
          ],
          [
           1,
           5.151666
          ],
          [
           1,
           4.268571
          ],
          [
           1,
           4.134285
          ],
          [
           1,
           4.82
          ],
          [
           1,
           5.424
          ],
          [
           1,
           4.984
          ],
          [
           1,
           4.102
          ],
          [
           1,
           4.205
          ],
          [
           1,
           4.1325
          ],
          [
           1,
           3.895
          ],
          [
           1,
           6.935
          ],
          [
           1,
           6.79
          ],
          [
           1,
           4.89
          ],
          [
           1,
           4.665
          ],
          [
           1,
           3.08
          ],
          [
           1,
           4.44
          ],
          [
           1,
           4.36
          ],
          [
           1,
           3.98
          ],
          [
           1,
           7
          ],
          [
           1,
           2.9
          ]
         ],
         "hovertemplate": "Region=%{x}<br>Total Spending (USD)=%{y}<br>NumberOfCustomers=%{customdata[0]}<br>AverageOrderValue=%{customdata[1]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "USA",
          "Canada",
          "Brazil",
          "France",
          "Ireland",
          "Germany",
          "United Kingdom",
          "Iran",
          "Czech Republic",
          "Malta",
          "Portugal",
          "India",
          "Kenya",
          "Austria",
          "Tunisia",
          "Comoros",
          "Georgia",
          "Argentina",
          "Chile",
          "Saudi Arabia",
          "Qatar",
          "Papua New Guinea",
          "Congo",
          "British Indian Ocean Territory (Chagos A",
          "Singapore",
          "Antigua and Barbuda",
          "Estonia",
          "Sweden",
          "Seychelles",
          "Korea",
          "Panama",
          "Hungary",
          "Maldives",
          "Saint Vincent and the Grenadines",
          "Madagascar",
          "Costa Rica",
          "Saint Martin",
          "Croatia",
          "Finland",
          "Netherlands",
          "Bhutan",
          "Saint Helena",
          "Macao",
          "Norway",
          "Gambia",
          "Denmark",
          "Australia",
          "Belgium",
          "Poland",
          "Italy",
          "Spain",
          "Albania",
          "Zambia",
          "Cyprus",
          "Dominican Republic",
          "Cambodia",
          "Samoa",
          "China",
          "Mauritius",
          "Slovakia (Slovak Republic)",
          "United States Virgin Islands",
          "Cote d'Ivoire",
          "Lesotho",
          "Israel",
          "Kyrgyz Republic",
          "United Arab Emirates",
          "Belize",
          "Cape Verde",
          "Guam",
          "Pakistan",
          "Tokelau",
          "Cocos (Keeling) Islands",
          "United States of America",
          "Guinea-Bissau",
          "Saint Pierre and Miquelon",
          "Vietnam",
          "Monaco",
          "Kazakhstan"
         ],
         "xaxis": "x",
         "y": [
          523.06,
          303.96,
          208.45,
          195.1,
          160.23,
          156.48,
          112.86,
          99.14,
          90.24,
          79.49,
          77.24,
          75.26,
          74.62,
          72.79,
          68.14,
          67.45,
          65.59,
          61.73,
          59.64,
          58.79,
          58.78,
          55.7,
          54.81,
          53.68,
          51.66,
          51.2,
          50.88,
          49.87,
          48.73,
          48.48,
          46,
          45.62,
          44.82,
          43.93,
          43.47,
          43.07,
          42.13,
          41.84,
          41.62,
          40.62,
          40.56,
          40.33,
          39.64,
          39.62,
          39.51,
          37.62,
          37.62,
          37.62,
          37.62,
          37.62,
          37.62,
          35.08,
          34.72,
          34.54,
          33.6,
          32.59,
          32.01,
          31.4,
          30.91,
          29.88,
          28.94,
          28.92,
          27.12,
          24.92,
          20.51,
          16.82,
          16.53,
          15.58,
          13.87,
          13.58,
          9.78,
          9.33,
          9.24,
          8.88,
          8.72,
          7.96,
          7,
          2.9
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Total Customer Spending by Region"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Region"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Total Spending (USD)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           523.06,
           1.058825
          ],
          [
           303.96,
           0.999868
          ],
          [
           208.45,
           1.068974
          ],
          [
           195.1,
           1.026842
          ],
          [
           160.23,
           2.427727
          ],
          [
           156.48,
           1.029473
          ],
          [
           112.86,
           0.99
          ],
          [
           99.14,
           4.130833
          ],
          [
           90.24,
           1.187368
          ],
          [
           79.49,
           4.675882
          ],
          [
           77.24,
           1.016315
          ],
          [
           75.26,
           1.017027
          ],
          [
           74.62,
           4.145555
          ],
          [
           72.79,
           1.582391
          ],
          [
           68.14,
           4.542666
          ],
          [
           67.45,
           3.747222
          ],
          [
           65.59,
           5.045384
          ],
          [
           61.73,
           1.435581
          ],
          [
           59.64,
           1.454634
          ],
          [
           58.79,
           4.899166
          ],
          [
           58.78,
           4.898333
          ],
          [
           55.7,
           4.641666
          ],
          [
           54.81,
           4.5675
          ],
          [
           53.68,
           4.473333
          ],
          [
           51.66,
           4.696363
          ],
          [
           51.2,
           4.654545
          ],
          [
           50.88,
           4.24
          ],
          [
           49.87,
           1.24675
          ],
          [
           48.73,
           6.09125
          ],
          [
           48.48,
           4.04
          ],
          [
           46,
           5.111111
          ],
          [
           45.62,
           1.200526
          ],
          [
           44.82,
           4.98
          ],
          [
           43.93,
           4.881111
          ],
          [
           43.47,
           3.6225
          ],
          [
           43.07,
           4.785555
          ],
          [
           42.13,
           3.240769
          ],
          [
           41.84,
           4.184
          ],
          [
           41.62,
           1.095263
          ],
          [
           40.62,
           1.068947
          ],
          [
           40.56,
           4.056
          ],
          [
           40.33,
           5.04125
          ],
          [
           39.64,
           3.964
          ],
          [
           39.62,
           1.042631
          ],
          [
           39.51,
           4.39
          ],
          [
           37.62,
           0.99
          ],
          [
           37.62,
           0.99
          ],
          [
           37.62,
           0.99
          ],
          [
           37.62,
           0.99
          ],
          [
           37.62,
           0.99
          ],
          [
           37.62,
           0.99
          ],
          [
           35.08,
           3.508
          ],
          [
           34.72,
           4.34
          ],
          [
           34.54,
           5.756666
          ],
          [
           33.6,
           4.8
          ],
          [
           32.59,
           4.655714
          ],
          [
           32.01,
           4.572857
          ],
          [
           31.4,
           6.28
          ],
          [
           30.91,
           5.151666
          ],
          [
           29.88,
           4.268571
          ],
          [
           28.94,
           4.134285
          ],
          [
           28.92,
           4.82
          ],
          [
           27.12,
           5.424
          ],
          [
           24.92,
           4.984
          ],
          [
           20.51,
           4.102
          ],
          [
           16.82,
           4.205
          ],
          [
           16.53,
           4.1325
          ],
          [
           15.58,
           3.895
          ],
          [
           13.87,
           6.935
          ],
          [
           13.58,
           6.79
          ],
          [
           9.78,
           4.89
          ],
          [
           9.33,
           4.665
          ],
          [
           9.24,
           3.08
          ],
          [
           8.88,
           4.44
          ],
          [
           8.72,
           4.36
          ],
          [
           7.96,
           3.98
          ],
          [
           7,
           7
          ],
          [
           2.9,
           2.9
          ]
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "Region=%{label}<br>NumberOfCustomers=%{value}<br>TotalSpending=%{customdata[0]}<br>AverageOrderValue=%{customdata[1]}<extra></extra>",
         "labels": [
          "USA",
          "Canada",
          "Brazil",
          "France",
          "Ireland",
          "Germany",
          "United Kingdom",
          "Iran",
          "Czech Republic",
          "Malta",
          "Portugal",
          "India",
          "Kenya",
          "Austria",
          "Tunisia",
          "Comoros",
          "Georgia",
          "Argentina",
          "Chile",
          "Saudi Arabia",
          "Qatar",
          "Papua New Guinea",
          "Congo",
          "British Indian Ocean Territory (Chagos A",
          "Singapore",
          "Antigua and Barbuda",
          "Estonia",
          "Sweden",
          "Seychelles",
          "Korea",
          "Panama",
          "Hungary",
          "Maldives",
          "Saint Vincent and the Grenadines",
          "Madagascar",
          "Costa Rica",
          "Saint Martin",
          "Croatia",
          "Finland",
          "Netherlands",
          "Bhutan",
          "Saint Helena",
          "Macao",
          "Norway",
          "Gambia",
          "Denmark",
          "Australia",
          "Belgium",
          "Poland",
          "Italy",
          "Spain",
          "Albania",
          "Zambia",
          "Cyprus",
          "Dominican Republic",
          "Cambodia",
          "Samoa",
          "China",
          "Mauritius",
          "Slovakia (Slovak Republic)",
          "United States Virgin Islands",
          "Cote d'Ivoire",
          "Lesotho",
          "Israel",
          "Kyrgyz Republic",
          "United Arab Emirates",
          "Belize",
          "Cape Verde",
          "Guam",
          "Pakistan",
          "Tokelau",
          "Cocos (Keeling) Islands",
          "United States of America",
          "Guinea-Bissau",
          "Saint Pierre and Miquelon",
          "Vietnam",
          "Monaco",
          "Kazakhstan"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "textinfo": "percent+label",
         "textposition": "inside",
         "type": "pie",
         "values": [
          13,
          8,
          6,
          5,
          4,
          4,
          3,
          2,
          2,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          1,
          2,
          2,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Number of Customers by Region"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def visualize_customer_spending():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'ChinookDW4'\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    \n",
    "    # Define the SQL query\n",
    "    sql_query = '''\n",
    "    SELECT \n",
    "        DimCustomer.Country AS Region,\n",
    "        COUNT(DISTINCT FactSales.CustomerKey) AS NumberOfCustomers,\n",
    "        SUM(FactSales.TotalAmount) AS TotalSpending,\n",
    "        AVG(FactSales.TotalAmount) AS AverageOrderValue\n",
    "    FROM \n",
    "        FactSales\n",
    "    JOIN \n",
    "        DimCustomer ON FactSales.CustomerKey = DimCustomer.CustomerKey\n",
    "    GROUP BY \n",
    "        DimCustomer.Country\n",
    "    ORDER BY \n",
    "        TotalSpending DESC;\n",
    "    '''\n",
    "    \n",
    "    # Fetch data into a pandas DataFrame\n",
    "    df = pd.read_sql(sql_query, conn)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    # Check if data is available\n",
    "    if df.empty:\n",
    "        print(\"No data available.\")\n",
    "        return\n",
    "    \n",
    "    # Data visualization using Plotly\n",
    "    # Bar chart of Total Spending by Region\n",
    "    fig = px.bar(\n",
    "        df, \n",
    "        x='Region', \n",
    "        y='TotalSpending', \n",
    "        title='Total Customer Spending by Region',\n",
    "        hover_data=['NumberOfCustomers', 'AverageOrderValue'],\n",
    "        labels={'TotalSpending': 'Total Spending (USD)', 'Region': 'Region'},\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis_tickangle=-45,\n",
    "        height=600,\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Optional: Pie chart of Number of Customers by Region\n",
    "    fig_pie = px.pie(\n",
    "        df, \n",
    "        names='Region', \n",
    "        values='NumberOfCustomers',\n",
    "        title='Number of Customers by Region',\n",
    "        hover_data=['TotalSpending', 'AverageOrderValue'],\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig_pie.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig_pie.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    visualize_customer_spending()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_39616\\756567358.py:39: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "customdata": [
          [
           10
          ],
          [
           11
          ],
          [
           6
          ],
          [
           6
          ],
          [
           9
          ],
          [
           6
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           6
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           5
          ],
          [
           6
          ],
          [
           6
          ],
          [
           5
          ],
          [
           5
          ],
          [
           4
          ]
         ],
         "hovertemplate": "Revenue (USD)=%{x}<br>Track Name=%{y}<br>QuantitySold=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          18.35,
          17.02,
          10.88,
          10.35,
          10.33,
          10.1,
          9.85,
          9.8,
          9.65,
          9.5,
          9.26,
          9.15,
          9.1,
          8.85,
          8.6,
          8.6,
          8.32,
          8.3,
          8.06,
          7.92
         ],
         "xaxis": "x",
         "y": [
          "Point another gun practice.",
          "We produce.",
          "Teach cause.",
          "Store relate best bad.",
          "Parent million fund dream.",
          "Assume usually activity table.",
          "Senior thought change example.",
          "Blue affect today blue summer.",
          "Box tree radio.",
          "Difference run science responsibility manager.",
          "Indicate surface wish teacher week.",
          "Finally institution character per left.",
          "Type can middle power present.",
          "Cell wife reduce.",
          "Whom answer service product describe.",
          "Stay these.",
          "Throw than social success herself.",
          "Family defense my maybe attack.",
          "Onto check street door.",
          "Leave voice year them administration."
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 700,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 20 Tracks by Revenue in 2023"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Revenue (USD)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Track Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def visualize_top_tracks():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'ChinookDW4'\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = pyodbc.connect(\n",
    "        'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "        f'SERVER={server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    \n",
    "    # Define the SQL query\n",
    "    sql_query = '''\n",
    "    SELECT \n",
    "        DimTrack.Name AS TrackName,\n",
    "        SUM(FactSales.Quantity) AS QuantitySold,\n",
    "        SUM(FactSales.TotalAmount) AS Revenue\n",
    "    FROM \n",
    "        FactSales\n",
    "    JOIN \n",
    "        DimTrack ON FactSales.TrackKey = DimTrack.TrackKey\n",
    "    JOIN \n",
    "        DimDate ON FactSales.DateKey = DimDate.DateKey\n",
    "    WHERE \n",
    "        DimDate.Year = 2023  -- Specify the desired year or range\n",
    "    GROUP BY \n",
    "        DimTrack.Name\n",
    "    ORDER BY \n",
    "        Revenue DESC;  -- Or use `QuantitySold DESC` for top quantity\n",
    "    '''\n",
    "    \n",
    "    # Fetch data into a pandas DataFrame\n",
    "    df = pd.read_sql(sql_query, conn)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    # Check if data is available\n",
    "    if df.empty:\n",
    "        print(\"No data available for the specified year.\")\n",
    "        return\n",
    "    \n",
    "    # Limit to Top 20 Tracks for better visualization\n",
    "    df_top = df.head(20)\n",
    "    \n",
    "    # Data visualization using Plotly\n",
    "    fig = px.bar(\n",
    "        df_top, \n",
    "        x='Revenue', \n",
    "        y='TrackName', \n",
    "        orientation='h',\n",
    "        title='Top 20 Tracks by Revenue in 2023',\n",
    "        hover_data=['QuantitySold'],\n",
    "        labels={'TrackName': 'Track Name', 'Revenue': 'Revenue (USD)'},\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        yaxis={'categoryorder':'total ascending'},\n",
    "        height=700,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    visualize_top_tracks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sys\n",
    "\n",
    "def connect_to_db(server, database):\n",
    "    \"\"\"Establishes a connection to the SQL Server database.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "            f'SERVER={server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Trusted_Connection=yes;'\n",
    "        )\n",
    "        return conn\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error connecting to database:\", e)\n",
    "        sys.exit(1)\n",
    "\n",
    "def get_dimensions(cursor):\n",
    "    \"\"\"Retrieves a list of dimension tables in the database.\"\"\"\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT TABLE_NAME\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_NAME LIKE 'Dim%'\n",
    "    \"\"\")\n",
    "    dimensions = [row.TABLE_NAME for row in cursor.fetchall()]\n",
    "    return dimensions\n",
    "\n",
    "def prompt_user_action(dimensions):\n",
    "    \"\"\"Prompts the user to choose normalization or denormalization.\"\"\"\n",
    "    print(\"Available dimensions:\")\n",
    "    for idx, dim in enumerate(dimensions, start=1):\n",
    "        print(f\"{idx}. {dim}\")\n",
    "\n",
    "    action = input(\"\\nDo you want to (1) Normalize or (2) Denormalize dimensions? Enter 1 or 2: \")\n",
    "    while action not in ['1', '2']:\n",
    "        action = input(\"Invalid input. Enter 1 for Normalize or 2 for Denormalize: \")\n",
    "\n",
    "    if action == '1':\n",
    "        # Normalization\n",
    "        print(\"\\nNormalization selected.\")\n",
    "        dim_to_normalize = input(\"Enter the number of the dimension you want to normalize: \")\n",
    "        try:\n",
    "            dim_index = int(dim_to_normalize) - 1\n",
    "            if dim_index < 0 or dim_index >= len(dimensions):\n",
    "                raise ValueError\n",
    "            selected_dim = dimensions[dim_index]\n",
    "        except ValueError:\n",
    "            print(\"Invalid selection.\")\n",
    "            sys.exit(1)\n",
    "        new_dim_name = input(\"Enter the name of the new dimension to create from normalization: \").strip()\n",
    "        return 'normalize', selected_dim, new_dim_name\n",
    "    else:\n",
    "        # Denormalization\n",
    "        print(\"\\nDenormalization selected.\")\n",
    "        dims_to_denormalize = input(\"Enter the numbers of the dimensions you want to denormalize (separated by commas): \")\n",
    "        try:\n",
    "            indices = [int(i.strip()) - 1 for i in dims_to_denormalize.split(',')]\n",
    "            if any(idx < 0 or idx >= len(dimensions) for idx in indices):\n",
    "                raise ValueError\n",
    "            selected_dims = [dimensions[idx] for idx in indices]\n",
    "        except ValueError:\n",
    "            print(\"Invalid selection.\")\n",
    "            sys.exit(1)\n",
    "        new_dim_name = input(\"Enter the name of the new dimension to create from denormalization: \").strip()\n",
    "        return 'denormalize', selected_dims, new_dim_name\n",
    "\n",
    "def validate_action(action, dims, cursor):\n",
    "    \"\"\"Validates if the normalization or denormalization makes sense.\"\"\"\n",
    "    if action == 'normalize':\n",
    "        # Check if the dimension has attributes that can be moved to a new dimension\n",
    "        dim = dims\n",
    "        cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{dim}'\")\n",
    "        columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "        if len(columns) <= 2:\n",
    "            print(f\"Dimension {dim} cannot be normalized further.\")\n",
    "            return False\n",
    "        return True\n",
    "    else:\n",
    "        # Check if dimensions can be combined\n",
    "        dims_to_combine = dims\n",
    "        # Ensure dimensions have no conflicting columns\n",
    "        all_columns = {}\n",
    "        for dim in dims_to_combine:\n",
    "            cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{dim}'\")\n",
    "            columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "            for col in columns:\n",
    "                if col in all_columns:\n",
    "                    print(f\"Conflicting column '{col}' found in dimensions. Cannot denormalize.\")\n",
    "                    return False\n",
    "                all_columns[col] = dim\n",
    "        return True\n",
    "\n",
    "def perform_normalization(cursor, conn, dim_to_normalize, new_dim_name):\n",
    "    \"\"\"Performs normalization by creating a new dimension and updating relationships.\"\"\"\n",
    "    # Example: Split DimTrack into DimTrack and DimGenre\n",
    "    # For simplicity, we'll assume the last column is the one to normalize out\n",
    "    cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{dim_to_normalize}'\")\n",
    "    columns = [row.COLUMN_NAME for row in cursor.fetchall()]\n",
    "    print(f\"Columns in {dim_to_normalize}: {columns}\")\n",
    "\n",
    "    # Prompt user to select columns to move to the new dimension\n",
    "    print(\"\\nSelect the columns to move to the new dimension:\")\n",
    "    for idx, col in enumerate(columns, start=1):\n",
    "        print(f\"{idx}. {col}\")\n",
    "    cols_to_move_input = input(\"Enter the numbers of the columns to move (separated by commas): \")\n",
    "    try:\n",
    "        indices = [int(i.strip()) - 1 for i in cols_to_move_input.split(',')]\n",
    "        if any(idx < 0 or idx >= len(columns) for idx in indices):\n",
    "            raise ValueError\n",
    "        cols_to_move = [columns[idx] for idx in indices]\n",
    "    except ValueError:\n",
    "        print(\"Invalid selection.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Proceed with normalization\n",
    "    cols_to_keep = [col for col in columns if col not in cols_to_move]\n",
    "    print(f\"Columns to keep in {dim_to_normalize}: {cols_to_keep}\")\n",
    "    print(f\"Columns to move to {new_dim_name}: {cols_to_move}\")\n",
    "\n",
    "    # Create the new dimension table\n",
    "    try:\n",
    "        # Create new dimension table\n",
    "        create_table_sql = f\"SELECT DISTINCT {', '.join(cols_to_move)} INTO {new_dim_name} FROM {dim_to_normalize}\"\n",
    "        cursor.execute(f\"IF OBJECT_ID('{new_dim_name}', 'U') IS NOT NULL DROP TABLE {new_dim_name}\")\n",
    "        cursor.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "        print(f\"Dimension {new_dim_name} created successfully.\")\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error creating new dimension:\", e)\n",
    "        conn.rollback()\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Update the original dimension table\n",
    "    try:\n",
    "        # Add foreign key column\n",
    "        fk_column = f\"{new_dim_name}ID\"\n",
    "        cursor.execute(f\"ALTER TABLE {dim_to_normalize} ADD {fk_column} INT\")\n",
    "        conn.commit()\n",
    "        print(f\"Foreign key column {fk_column} added to {dim_to_normalize}.\")\n",
    "\n",
    "        # Update foreign key values\n",
    "        update_fk_sql = f\"\"\"\n",
    "        UPDATE {dim_to_normalize}\n",
    "        SET {fk_column} = nd.ID\n",
    "        FROM {new_dim_name} nd\n",
    "        WHERE {\" AND \".join([f\"{dim_to_normalize}.{col} = nd.{col}\" for col in cols_to_move])}\n",
    "        \"\"\"\n",
    "        cursor.execute(update_fk_sql)\n",
    "        conn.commit()\n",
    "        print(f\"Foreign key values in {dim_to_normalize} updated.\")\n",
    "\n",
    "        # Remove moved columns from original dimension\n",
    "        for col in cols_to_move:\n",
    "            cursor.execute(f\"ALTER TABLE {dim_to_normalize} DROP COLUMN {col}\")\n",
    "        conn.commit()\n",
    "        print(f\"Columns {', '.join(cols_to_move)} removed from {dim_to_normalize}.\")\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error updating original dimension:\", e)\n",
    "        conn.rollback()\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Update Fact table foreign keys if necessary (not implemented here)\n",
    "    # Additional steps would be required to update related fact tables and constraints.\n",
    "\n",
    "def perform_denormalization(cursor, conn, dims_to_denormalize, new_dim_name):\n",
    "    \"\"\"Performs denormalization by combining dimensions into a new dimension.\"\"\"\n",
    "    # Get all columns from the dimensions\n",
    "    all_columns = []\n",
    "    for dim in dims_to_denormalize:\n",
    "        cursor.execute(f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{dim}'\")\n",
    "        cols = [f\"{dim}.{row.COLUMN_NAME}\" for row in cursor.fetchall()]\n",
    "        all_columns.extend(cols)\n",
    "\n",
    "    # Create the new dimension table\n",
    "    try:\n",
    "        join_conditions = []\n",
    "        for i in range(len(dims_to_denormalize) - 1):\n",
    "            dim1 = dims_to_denormalize[i]\n",
    "            dim2 = dims_to_denormalize[i + 1]\n",
    "            # Assuming the dimensions have a common key for joining\n",
    "            join_condition = f\"{dim1}.CommonKey = {dim2}.CommonKey\"\n",
    "            join_conditions.append(join_condition)\n",
    "\n",
    "        from_clause = ' JOIN '.join([dim for dim in dims_to_denormalize])\n",
    "        if join_conditions:\n",
    "            from_clause += ' ON ' + ' AND '.join(join_conditions)\n",
    "\n",
    "        create_table_sql = f\"SELECT DISTINCT {', '.join(all_columns)} INTO {new_dim_name} FROM {from_clause}\"\n",
    "        cursor.execute(f\"IF OBJECT_ID('{new_dim_name}', 'U') IS NOT NULL DROP TABLE {new_dim_name}\")\n",
    "        cursor.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "        print(f\"Dimension {new_dim_name} created successfully by denormalizing {', '.join(dims_to_denormalize)}.\")\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"Error creating new dimension:\", e)\n",
    "        conn.rollback()\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Update Fact table foreign keys if necessary (not implemented here)\n",
    "    # Additional steps would be required to update related fact tables and constraints.\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    server = 'DPC2023'  # Replace with your server name\n",
    "    database = 'ChinookDW4'\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = connect_to_db(server, database)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve dimensions\n",
    "    dimensions = get_dimensions(cursor)\n",
    "    if not dimensions:\n",
    "        print(\"No dimension tables found in the database.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Prompt user for action\n",
    "    action, dims, new_dim_name = prompt_user_action(dimensions)\n",
    "\n",
    "    # Validate action\n",
    "    is_valid = validate_action(action, dims, cursor)\n",
    "    if not is_valid:\n",
    "        print(\"The requested operation is not valid. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Perform action\n",
    "    if action == 'normalize':\n",
    "        perform_normalization(cursor, conn, dims, new_dim_name)\n",
    "    else:\n",
    "        perform_denormalization(cursor, conn, dims, new_dim_name)\n",
    "\n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"\\nSchema modification completed successfully.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dash\n",
      "  Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (65.6.3)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (4.4.0)\n",
      "Collecting dash-table==5.0.0\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (4.11.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (2.2.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from dash) (1.5.6)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.2)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Werkzeug<3.1->dash) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dash) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dash) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dash) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dash) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->Flask<3.1,>=1.0.4->dash) (0.4.6)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, dash\n",
      "Successfully installed dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts dash-generate-components.exe, dash-update-components.exe and renderer.exe are installed in 'C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install dash plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to 'ChinookDW4' on server 'DPC2023'.\n",
      "\n",
      "Fetching FactSales Table...\n",
      "Fetched data for table 'FactSales' using query: SELECT * FROM FactSales...\n",
      "Columns in 'FactSales': ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount']\n",
      "\n",
      "Sample data from 'FactSales':\n",
      "   SalesKey  InvoiceLineId  DateKey  CustomerKey  TrackKey  AlbumKey  \\\n",
      "0     20261            579     3322         2393     31580      3146   \n",
      "1     20262              1     3224         2348     31581      3147   \n",
      "2     20263           1154     3420         2379     31581      3147   \n",
      "3     20264           1728     3516         2359     31582      3148   \n",
      "4     20265              2     3224         2348     31583      3148   \n",
      "\n",
      "   GenreKey  MediaTypeKey  EmployeeKey  Quantity  UnitPrice  TotalAmount  \n",
      "0       231            49           82         1       0.99         0.99  \n",
      "1       231            50           82         1       0.99         0.99  \n",
      "2       231            50           80         1       0.99         0.99  \n",
      "3       231            50           81         1       0.99         0.99  \n",
      "4       231            50           82         1       0.99         0.99  \n",
      "\n",
      "\n",
      "Fetching DimDate Table...\n",
      "Fetched data for table 'DimDate' using query: SELECT * FROM DimDate...\n",
      "Columns in 'DimDate': ['DateKey', 'Date', 'Day', 'Month', 'Year', 'Quarter']\n",
      "\n",
      "Sample data from 'DimDate':\n",
      "   DateKey        Date  Day  Month  Year  Quarter\n",
      "0     3215  2019-11-19   19     11  2019        4\n",
      "1     3216  2020-01-16   16      1  2020        1\n",
      "2     3217  2020-01-22   22      1  2020        1\n",
      "3     3218  2020-04-09    9      4  2020        2\n",
      "4     3219  2020-04-21   21      4  2020        2\n",
      "\n",
      "\n",
      "Fetching DimCustomer Table...\n",
      "Fetched data for table 'DimCustomer' using query: SELECT * FROM DimCustomer...\n",
      "Columns in 'DimCustomer': ['CustomerKey', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode']\n",
      "\n",
      "Sample data from 'DimCustomer':\n",
      "   CustomerKey  CustomerId  FirstName     LastName  \\\n",
      "0         2347           1       Luís    Gonçalves   \n",
      "1         2348           2     Leonie       Köhler   \n",
      "2         2349           3   François     Tremblay   \n",
      "3         2350           4      Bjørn       Hansen   \n",
      "4         2351           5  František  Wichterlová   \n",
      "\n",
      "                                            Company  \\\n",
      "0  Embraer - Empresa Brasileira de Aeronáutica S.A.   \n",
      "1                                              None   \n",
      "2                                              None   \n",
      "3                                              None   \n",
      "4                                  JetBrains s.r.o.   \n",
      "\n",
      "                           Address                 City State         Country  \\\n",
      "0  Av. Brigadeiro Faria Lima, 2170  São José dos Campos    SP          Brazil   \n",
      "1          Theodor-Heuss-Straße 34            Stuttgart  None         Germany   \n",
      "2                1498 rue Bélanger             Montréal    QC          Canada   \n",
      "3                 Ullevålsveien 14                 Oslo  None          Norway   \n",
      "4                    Klanova 9/506               Prague  None  Czech Republic   \n",
      "\n",
      "  PostalCode  \n",
      "0  12227-000  \n",
      "1      70174  \n",
      "2    H2G 1A7  \n",
      "3       0171  \n",
      "4      14700  \n",
      "\n",
      "\n",
      "Fetching DimTrack Table...\n",
      "Fetched data for table 'DimTrack' using query: SELECT * FROM DimTrack...\n",
      "Columns in 'DimTrack': ['TrackKey', 'TrackId', 'Name', 'AlbumKey', 'MediaTypeKey', 'GenreKey', 'Composer', 'Milliseconds', 'Bytes']\n",
      "\n",
      "Sample data from 'DimTrack':\n",
      "   TrackKey  TrackId                                     Name  AlbumKey  \\\n",
      "0     31580        1  For Those About To Rock (We Salute You)      3146   \n",
      "1     31581        2                        Balls to the Wall      3147   \n",
      "2     31582        3                          Fast As a Shark      3148   \n",
      "3     31583        4                        Restless and Wild      3148   \n",
      "4     31584        5                     Princess of the Dawn      3148   \n",
      "\n",
      "   MediaTypeKey  GenreKey                                           Composer  \\\n",
      "0            49       231          Angus Young, Malcolm Young, Brian Johnson   \n",
      "1            50       231  U. Dirkschneider, W. Hoffmann, H. Frank, P. Ba...   \n",
      "2            50       231  F. Baltes, S. Kaufman, U. Dirkscneider & W. Ho...   \n",
      "3            50       231  F. Baltes, R.A. Smith-Diesel, S. Kaufman, U. D...   \n",
      "4            50       231                         Deaffy & R.A. Smith-Diesel   \n",
      "\n",
      "   Milliseconds     Bytes  \n",
      "0        343719  11170334  \n",
      "1        342562   5510424  \n",
      "2        230619   3990994  \n",
      "3        252051   4331779  \n",
      "4        375418   6290521  \n",
      "\n",
      "\n",
      "Fetching DimAlbum Table...\n",
      "Fetched data for table 'DimAlbum' using query: SELECT * FROM DimAlbum...\n",
      "Columns in 'DimAlbum': ['AlbumKey', 'AlbumId', 'Title', 'ArtistKey']\n",
      "\n",
      "Sample data from 'DimAlbum':\n",
      "   AlbumKey  AlbumId                                  Title  ArtistKey\n",
      "0      3146        1  For Those About To Rock We Salute You       2488\n",
      "1      3147        2                      Balls to the Wall       2489\n",
      "2      3148        3                      Restless and Wild       2489\n",
      "3      3149        4                      Let There Be Rock       2488\n",
      "4      3150        5                               Big Ones       2490\n",
      "\n",
      "\n",
      "Fetching DimArtist Table...\n",
      "Fetched data for table 'DimArtist' using query: SELECT ArtistKey, Name AS ArtistName FROM DimArtis...\n",
      "Columns in 'DimArtist': ['ArtistKey', 'ArtistName']\n",
      "\n",
      "Sample data from 'DimArtist':\n",
      "   ArtistKey         ArtistName\n",
      "0       2488              AC/DC\n",
      "1       2489             Accept\n",
      "2       2490          Aerosmith\n",
      "3       2491  Alanis Morissette\n",
      "4       2492    Alice In Chains\n",
      "\n",
      "\n",
      "Fetching DimGenre Table...\n",
      "Fetched data for table 'DimGenre' using query: SELECT GenreKey, Name AS GenreName FROM DimGenre...\n",
      "Columns in 'DimGenre': ['GenreKey', 'GenreName']\n",
      "\n",
      "Sample data from 'DimGenre':\n",
      "   GenreKey           GenreName\n",
      "0       231                Rock\n",
      "1       232                Jazz\n",
      "2       233               Metal\n",
      "3       234  Alternative & Punk\n",
      "4       235       Rock And Roll\n",
      "\n",
      "\n",
      "Fetching DimMediaType Table...\n",
      "Fetched data for table 'DimMediaType' using query: SELECT MediaTypeKey, Name AS MediaTypeName FROM Di...\n",
      "Columns in 'DimMediaType': ['MediaTypeKey', 'MediaTypeName']\n",
      "\n",
      "Sample data from 'DimMediaType':\n",
      "   MediaTypeKey                MediaTypeName\n",
      "0            49              MPEG audio file\n",
      "1            50     Protected AAC audio file\n",
      "2            51  Protected MPEG-4 video file\n",
      "3            52     Purchased AAC audio file\n",
      "4            53               AAC audio file\n",
      "\n",
      "\n",
      "Fetching DimEmployee Table...\n",
      "Fetched data for table 'DimEmployee' using query: SELECT EmployeeKey, FirstName, LastName FROM DimEm...\n",
      "Columns in 'DimEmployee': ['EmployeeKey', 'FirstName', 'LastName']\n",
      "\n",
      "Sample data from 'DimEmployee':\n",
      "   EmployeeKey FirstName LastName\n",
      "0           78    Andrew    Adams\n",
      "1           79     Nancy  Edwards\n",
      "2           80      Jane  Peacock\n",
      "3           81  Margaret     Park\n",
      "4           82     Steve  Johnson\n",
      "\n",
      "\n",
      "\n",
      "All tables fetched successfully.\n",
      "Merged with DimDate.\n",
      "Columns after merging with DimDate: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter']\n",
      "\n",
      "Merged with DimCustomer.\n",
      "Columns after merging with DimCustomer: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode']\n",
      "\n",
      "Merged with DimTrack.\n",
      "Columns after merging with DimTrack: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes']\n",
      "\n",
      "Merged with DimAlbum.\n",
      "Columns after merging with DimAlbum: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes', 'AlbumId', 'Title', 'ArtistKey']\n",
      "\n",
      "Merged with DimArtist.\n",
      "Columns after merging with DimArtist: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes', 'AlbumId', 'Title', 'ArtistKey', 'ArtistName']\n",
      "\n",
      "Merged with DimGenre.\n",
      "Columns after merging with DimGenre: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes', 'AlbumId', 'Title', 'ArtistKey', 'ArtistName', 'GenreName']\n",
      "\n",
      "Merged with DimMediaType.\n",
      "Columns after merging with DimMediaType: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes', 'AlbumId', 'Title', 'ArtistKey', 'ArtistName', 'GenreName', 'MediaTypeName']\n",
      "\n",
      "Merged with DimEmployee.\n",
      "Columns after merging with DimEmployee: ['SalesKey', 'InvoiceLineId', 'DateKey', 'CustomerKey', 'TrackKey', 'AlbumKey', 'GenreKey', 'MediaTypeKey', 'EmployeeKey', 'Quantity', 'UnitPrice', 'TotalAmount', 'Date', 'Day', 'Month', 'Year', 'Quarter', 'CustomerId', 'FirstName_x', 'LastName_x', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'TrackId', 'Name', 'AlbumKey_dim_track', 'MediaTypeKey_dim_track', 'GenreKey_dim_track', 'Composer', 'Milliseconds', 'Bytes', 'AlbumId', 'Title', 'ArtistKey', 'ArtistName', 'GenreName', 'MediaTypeName', 'FirstName_y', 'LastName_y']\n",
      "\n",
      "Successfully merged fact and dimension tables.\n",
      "OLAP cube created successfully.\n",
      "OLAP cube saved to 'olap_cube.csv'.\n",
      "\n",
      "Performing Slice Operation: Total Rock Sales in 2023\n",
      "Total Rock Sales in 2023:\n",
      "Quarter  Month  Day\n",
      "1        1      2      0.00\n",
      "                3      0.00\n",
      "                4      0.00\n",
      "                5      0.00\n",
      "                7      0.00\n",
      "                       ... \n",
      "4        12     24     1.98\n",
      "                25     0.00\n",
      "                27     3.96\n",
      "                28     0.00\n",
      "                30     0.00\n",
      "Length: 246, dtype: float64\n",
      "\n",
      "Performing Dice Operation: Total Rock and Jazz Sales in Q1 and Q2 of 2023\n",
      "Total Rock and Jazz Sales in Q1 and Q2 of 2023:\n",
      "GenreName  Quarter\n",
      "Jazz       1           3.96\n",
      "Rock       1          58.41\n",
      "           2          35.64\n",
      "Name: TotalAmount, dtype: float64\n",
      "\n",
      "Performing Drill Down Operation: Monthly Rock Sales in 2023\n",
      "Monthly Rock Sales in 2023:\n",
      "Month\n",
      "1     16.83\n",
      "2     23.76\n",
      "3     17.82\n",
      "4      5.94\n",
      "5     24.75\n",
      "6      4.95\n",
      "7     11.88\n",
      "8      2.97\n",
      "9     17.82\n",
      "10    17.82\n",
      "11     1.98\n",
      "12     9.90\n",
      "Name: TotalAmount, dtype: float64\n",
      "\n",
      "Performing Roll Up Operation: Quarterly Sales in 2023\n",
      "Quarterly Sales in 2023:\n",
      "Quarter\n",
      "1    1406.65\n",
      "2    1569.38\n",
      "3    1707.57\n",
      "4    1514.04\n",
      "Name: TotalAmount, dtype: float64\n",
      "\n",
      "OLAP process completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "def create_db_engine(server, database):\n",
    "    \"\"\"\n",
    "    Creates a SQLAlchemy engine for connecting to the SQL Server database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define the connection string using URL.create for better handling\n",
    "        connection_url = URL.create(\n",
    "            \"mssql+pyodbc\",\n",
    "            username=\"\",  # If using Windows Authentication, leave blank\n",
    "            password=\"\",  # If using Windows Authentication, leave blank\n",
    "            host=server,\n",
    "            database=database,\n",
    "            query={\n",
    "                \"driver\": \"ODBC Driver 17 for SQL Server\",\n",
    "                \"trusted_connection\": \"yes\"\n",
    "            }\n",
    "        )\n",
    "        engine = create_engine(connection_url, fast_executemany=True)\n",
    "        # Test the connection\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(\"SELECT 1\")\n",
    "        print(f\"Successfully connected to '{database}' on server '{server}'.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to '{database}' on server '{server}': {e}\")\n",
    "        raise\n",
    "\n",
    "def fetch_table(engine, query, table_name):\n",
    "    \"\"\"\n",
    "    Fetches data from the database using the provided SQL query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(f\"Fetched data for table '{table_name}' using query: {query[:50]}...\")\n",
    "        print(f\"Columns in '{table_name}': {list(df.columns)}\\n\")\n",
    "        print(f\"Sample data from '{table_name}':\")\n",
    "        print(df.head())\n",
    "        print(\"\\n\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for table '{table_name}': {e}\")\n",
    "        raise\n",
    "\n",
    "def build_olap_cube(fact_sales, dim_date, dim_customer, dim_track, dim_album, dim_artist, dim_genre, dim_mediatype, dim_employee):\n",
    "    \"\"\"\n",
    "    Builds an OLAP cube using pandas pivot tables.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List of required keys and their corresponding DataFrames\n",
    "        required_keys = {\n",
    "            'DateKey': dim_date,\n",
    "            'CustomerKey': dim_customer,\n",
    "            'TrackKey': dim_track,\n",
    "            'AlbumKey': dim_album,\n",
    "            'ArtistKey': dim_artist,\n",
    "            'GenreKey': dim_genre,\n",
    "            'MediaTypeKey': dim_mediatype,\n",
    "            'EmployeeKey': dim_employee\n",
    "        }\n",
    "\n",
    "        # Verify that all required keys exist in the respective DataFrames\n",
    "        missing_columns = []\n",
    "        for key, df in required_keys.items():\n",
    "            if key not in df.columns:\n",
    "                missing_columns.append((key, df))\n",
    "\n",
    "        if missing_columns:\n",
    "            for key, df in missing_columns:\n",
    "                print(f\"Error: Column '{key}' is missing in the corresponding DataFrame.\")\n",
    "            raise KeyError(\"One or more required columns are missing.\")\n",
    "\n",
    "        # Ensure 'AlbumKey' is of the same data type in both DataFrames\n",
    "        fact_sales['AlbumKey'] = pd.to_numeric(fact_sales['AlbumKey'], errors='coerce')\n",
    "        dim_album['AlbumKey'] = pd.to_numeric(dim_album['AlbumKey'], errors='coerce')\n",
    "\n",
    "        # Check for nulls after type conversion\n",
    "        if fact_sales['AlbumKey'].isnull().any():\n",
    "            num_nulls = fact_sales['AlbumKey'].isnull().sum()\n",
    "            print(f\"Warning: 'AlbumKey' in FactSales contains {num_nulls} null values. These rows will be excluded.\")\n",
    "            fact_sales = fact_sales.dropna(subset=['AlbumKey'])\n",
    "\n",
    "        if dim_album['AlbumKey'].isnull().any():\n",
    "            num_nulls = dim_album['AlbumKey'].isnull().sum()\n",
    "            print(f\"Warning: 'AlbumKey' in DimAlbum contains {num_nulls} null values. These rows will be excluded.\")\n",
    "            dim_album = dim_album.dropna(subset=['AlbumKey'])\n",
    "\n",
    "        # Convert 'AlbumKey' to integer type\n",
    "        fact_sales['AlbumKey'] = fact_sales['AlbumKey'].astype(int)\n",
    "        dim_album['AlbumKey'] = dim_album['AlbumKey'].astype(int)\n",
    "\n",
    "        # Verify 'AlbumKey' is present after handling\n",
    "        if 'AlbumKey' not in fact_sales.columns:\n",
    "            print(\"Error: 'AlbumKey' is missing in FactSales after processing.\")\n",
    "            raise KeyError(\"'AlbumKey' is missing in FactSales after processing.\")\n",
    "\n",
    "        if 'AlbumKey' not in dim_album.columns:\n",
    "            print(\"Error: 'AlbumKey' is missing in DimAlbum.\")\n",
    "            raise KeyError(\"'AlbumKey' is missing in DimAlbum.\")\n",
    "\n",
    "        # Merge fact table with DimDate\n",
    "        df = fact_sales.merge(dim_date, how='left', on='DateKey')\n",
    "        print(\"Merged with DimDate.\")\n",
    "        print(f\"Columns after merging with DimDate: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimCustomer\n",
    "        df = df.merge(dim_customer, how='left', on='CustomerKey')\n",
    "        print(\"Merged with DimCustomer.\")\n",
    "        print(f\"Columns after merging with DimCustomer: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimTrack\n",
    "        df = df.merge(dim_track, how='left', on='TrackKey', suffixes=('', '_dim_track'))\n",
    "        print(\"Merged with DimTrack.\")\n",
    "        print(f\"Columns after merging with DimTrack: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimAlbum\n",
    "        df = df.merge(dim_album, how='left', on='AlbumKey', suffixes=('', '_dim_album'))\n",
    "        print(\"Merged with DimAlbum.\")\n",
    "        print(f\"Columns after merging with DimAlbum: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimArtist\n",
    "        df = df.merge(dim_artist, how='left', on='ArtistKey')\n",
    "        print(\"Merged with DimArtist.\")\n",
    "        print(f\"Columns after merging with DimArtist: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimGenre\n",
    "        df = df.merge(dim_genre, how='left', on='GenreKey')\n",
    "        print(\"Merged with DimGenre.\")\n",
    "        print(f\"Columns after merging with DimGenre: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimMediaType\n",
    "        df = df.merge(dim_mediatype, how='left', on='MediaTypeKey')\n",
    "        print(\"Merged with DimMediaType.\")\n",
    "        print(f\"Columns after merging with DimMediaType: {list(df.columns)}\\n\")\n",
    "\n",
    "        # Merge with DimEmployee\n",
    "        df = df.merge(dim_employee, how='left', on='EmployeeKey')\n",
    "        print(\"Merged with DimEmployee.\")\n",
    "        print(f\"Columns after merging with DimEmployee: {list(df.columns)}\\n\")\n",
    "\n",
    "        print(\"Successfully merged fact and dimension tables.\")\n",
    "\n",
    "        # Check if 'TotalAmount' exists\n",
    "        if 'TotalAmount' not in df.columns:\n",
    "            print(\"Error: Column 'TotalAmount' is missing in the merged DataFrame.\")\n",
    "            raise KeyError(\"Column 'TotalAmount' is missing.\")\n",
    "\n",
    "        # Create a pivot table (OLAP cube)\n",
    "        cube = pd.pivot_table(\n",
    "            df,\n",
    "            index=['Year', 'Quarter', 'Month', 'Day'],\n",
    "            columns=['GenreName', 'MediaTypeName', 'ArtistName'],\n",
    "            values='TotalAmount',\n",
    "            aggfunc=np.sum,\n",
    "            fill_value=0\n",
    "        )\n",
    "        print(\"OLAP cube created successfully.\")\n",
    "        return cube, df\n",
    "    except KeyError as ke:\n",
    "        print(f\"Key Error: {ke}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error building OLAP cube: {e}\")\n",
    "        raise\n",
    "\n",
    "def perform_olap_operations(cube, df):\n",
    "    \"\"\"\n",
    "    Demonstrates various OLAP operations on the cube.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Example 1: Slice - Total sales for Genre 'Rock' across all Media Types and Artists for Year 2023\n",
    "        print(\"\\nPerforming Slice Operation: Total Rock Sales in 2023\")\n",
    "        if 2023 not in cube.index.get_level_values('Year'):\n",
    "            print(\"Year 2023 not found in the data.\")\n",
    "        else:\n",
    "            try:\n",
    "                rock_sales_2023 = cube.loc[2023].xs('Rock', level='GenreName', axis=1).sum(axis=1)\n",
    "                print(\"Total Rock Sales in 2023:\")\n",
    "                print(rock_sales_2023)\n",
    "            except KeyError:\n",
    "                print(\"Genre 'Rock' not found in the data.\")\n",
    "\n",
    "        # Example 2: Dice - Total sales for Genre 'Rock' and 'Jazz' in Q1 and Q2 of 2023\n",
    "        print(\"\\nPerforming Dice Operation: Total Rock and Jazz Sales in Q1 and Q2 of 2023\")\n",
    "        genres = ['Rock', 'Jazz']\n",
    "        quarters = [1, 2]\n",
    "        dice_sales = df[\n",
    "            (df['GenreName'].isin(genres)) &\n",
    "            (df['Year'] == 2023) &\n",
    "            (df['Quarter'].isin(quarters))\n",
    "        ].groupby(['GenreName', 'Quarter'])['TotalAmount'].sum()\n",
    "        if dice_sales.empty:\n",
    "            print(\"No sales data found for the specified genres and quarters.\")\n",
    "        else:\n",
    "            print(\"Total Rock and Jazz Sales in Q1 and Q2 of 2023:\")\n",
    "            print(dice_sales)\n",
    "\n",
    "        # Example 3: Drill Down - Monthly sales for Genre 'Rock' in 2023\n",
    "        print(\"\\nPerforming Drill Down Operation: Monthly Rock Sales in 2023\")\n",
    "        rock_monthly_sales = df[\n",
    "            (df['GenreName'] == 'Rock') &\n",
    "            (df['Year'] == 2023)\n",
    "        ].groupby(['Month'])['TotalAmount'].sum()\n",
    "        if rock_monthly_sales.empty:\n",
    "            print(\"No Rock sales data found for 2023.\")\n",
    "        else:\n",
    "            print(\"Monthly Rock Sales in 2023:\")\n",
    "            print(rock_monthly_sales)\n",
    "\n",
    "        # Example 4: Roll Up - Quarterly sales for all genres in 2023\n",
    "        print(\"\\nPerforming Roll Up Operation: Quarterly Sales in 2023\")\n",
    "        quarterly_sales = df[\n",
    "            (df['Year'] == 2023)\n",
    "        ].groupby(['Quarter'])['TotalAmount'].sum()\n",
    "        if quarterly_sales.empty:\n",
    "            print(\"No sales data found for 2023.\")\n",
    "        else:\n",
    "            print(\"Quarterly Sales in 2023:\")\n",
    "            print(quarterly_sales)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error performing OLAP operations: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    # Database connection parameters\n",
    "    source_server = 'DPC2023'  # Replace with your server name\n",
    "    target_database = 'ChinookDW4'  # Replace with your target database name\n",
    "\n",
    "    try:\n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_db_engine(source_server, target_database)\n",
    "\n",
    "        # Define SQL queries to fetch dimension and fact tables\n",
    "        queries = {\n",
    "            'FactSales': \"SELECT * FROM FactSales\",\n",
    "            'DimDate': \"SELECT * FROM DimDate\",\n",
    "            'DimCustomer': \"SELECT * FROM DimCustomer\",\n",
    "            'DimTrack': \"SELECT * FROM DimTrack\",\n",
    "            'DimAlbum': \"SELECT * FROM DimAlbum\",\n",
    "            'DimArtist': \"SELECT ArtistKey, Name AS ArtistName FROM DimArtist\",\n",
    "            'DimGenre': \"SELECT GenreKey, Name AS GenreName FROM DimGenre\",\n",
    "            'DimMediaType': \"SELECT MediaTypeKey, Name AS MediaTypeName FROM DimMediaType\",\n",
    "            'DimEmployee': \"SELECT EmployeeKey, FirstName, LastName FROM DimEmployee\"\n",
    "        }\n",
    "\n",
    "        # Fetch all tables with diagnostic print statements\n",
    "        print(\"\\nFetching FactSales Table...\")\n",
    "        fact_sales = fetch_table(engine, queries['FactSales'], 'FactSales')\n",
    "\n",
    "        print(\"Fetching DimDate Table...\")\n",
    "        dim_date = fetch_table(engine, queries['DimDate'], 'DimDate')\n",
    "\n",
    "        print(\"Fetching DimCustomer Table...\")\n",
    "        dim_customer = fetch_table(engine, queries['DimCustomer'], 'DimCustomer')\n",
    "\n",
    "        print(\"Fetching DimTrack Table...\")\n",
    "        dim_track = fetch_table(engine, queries['DimTrack'], 'DimTrack')\n",
    "\n",
    "        print(\"Fetching DimAlbum Table...\")\n",
    "        dim_album = fetch_table(engine, queries['DimAlbum'], 'DimAlbum')\n",
    "\n",
    "        print(\"Fetching DimArtist Table...\")\n",
    "        dim_artist = fetch_table(engine, queries['DimArtist'], 'DimArtist')\n",
    "\n",
    "        print(\"Fetching DimGenre Table...\")\n",
    "        dim_genre = fetch_table(engine, queries['DimGenre'], 'DimGenre')\n",
    "\n",
    "        print(\"Fetching DimMediaType Table...\")\n",
    "        dim_mediatype = fetch_table(engine, queries['DimMediaType'], 'DimMediaType')\n",
    "\n",
    "        print(\"Fetching DimEmployee Table...\")\n",
    "        dim_employee = fetch_table(engine, queries['DimEmployee'], 'DimEmployee')\n",
    "\n",
    "        print(\"\\nAll tables fetched successfully.\")\n",
    "\n",
    "        # Build OLAP cube\n",
    "        cube, merged_df = build_olap_cube(\n",
    "            fact_sales,\n",
    "            dim_date,\n",
    "            dim_customer,\n",
    "            dim_track,\n",
    "            dim_album,\n",
    "            dim_artist,\n",
    "            dim_genre,\n",
    "            dim_mediatype,\n",
    "            dim_employee\n",
    "        )\n",
    "\n",
    "        # Save the cube to a CSV file (optional)\n",
    "        try:\n",
    "            cube.to_csv('olap_cube.csv')\n",
    "            print(\"OLAP cube saved to 'olap_cube.csv'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving OLAP cube to CSV: {e}\")\n",
    "\n",
    "        # Perform OLAP operations\n",
    "        perform_olap_operations(cube, merged_df)\n",
    "\n",
    "        print(\"\\nOLAP process completed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the OLAP process: {e}\")\n",
    "        print(\"Please check the connection parameters and ensure that the database is accessible.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
